{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>258</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.926</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>148</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.605</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>9</td>\n",
       "      <td>165</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.302</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "254              12                      92              62               7   \n",
       "577               2                     118              80               0   \n",
       "673               3                     123             100              35   \n",
       "311               0                     106              70              37   \n",
       "355               9                     165              88               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "254      258  27.6              0.926   44             1  \n",
       "577        0  42.9              0.693   21             1  \n",
       "673      240  57.3              0.880   22             0  \n",
       "311      148  39.4              0.605   22             0  \n",
       "355        0  30.4              0.302   49             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.829\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 0.6825 - accuracy: 0.5823 - val_loss: 0.6964 - val_accuracy: 0.5781\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.6193 - val_loss: 0.6936 - val_accuracy: 0.5885\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.6398 - val_loss: 0.6910 - val_accuracy: 0.6042\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.6356 - val_loss: 0.6887 - val_accuracy: 0.6250\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6410 - val_loss: 0.6865 - val_accuracy: 0.6406\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6664 - val_loss: 0.6845 - val_accuracy: 0.6406\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.6631 - val_loss: 0.6827 - val_accuracy: 0.6406\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6530 - val_loss: 0.6810 - val_accuracy: 0.6458\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6818 - val_loss: 0.6794 - val_accuracy: 0.6406\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.6390 - val_loss: 0.6779 - val_accuracy: 0.6406\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6801 - val_loss: 0.6766 - val_accuracy: 0.6406\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6479 - val_loss: 0.6753 - val_accuracy: 0.6458\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6679 - val_loss: 0.6741 - val_accuracy: 0.6458\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6548 - val_loss: 0.6729 - val_accuracy: 0.6458\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.6587 - val_loss: 0.6719 - val_accuracy: 0.6458\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6515 - val_loss: 0.6709 - val_accuracy: 0.6406\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6489 - val_loss: 0.6699 - val_accuracy: 0.6406\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6624 - val_loss: 0.6690 - val_accuracy: 0.6406\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6451 - val_loss: 0.6681 - val_accuracy: 0.6406\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6636 - val_loss: 0.6673 - val_accuracy: 0.6406\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6735 - val_loss: 0.6665 - val_accuracy: 0.6406\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6361 - val_loss: 0.6657 - val_accuracy: 0.6406\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6248 - val_loss: 0.6650 - val_accuracy: 0.6406\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6440 - val_loss: 0.6642 - val_accuracy: 0.6406\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6481 - val_loss: 0.6635 - val_accuracy: 0.6406\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6557 - val_loss: 0.6629 - val_accuracy: 0.6406\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6585 - val_loss: 0.6622 - val_accuracy: 0.6406\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6369 - val_loss: 0.6616 - val_accuracy: 0.6406\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6395 - val_loss: 0.6609 - val_accuracy: 0.6406\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6560 - val_loss: 0.6603 - val_accuracy: 0.6406\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6676 - val_loss: 0.6597 - val_accuracy: 0.6406\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6758 - val_loss: 0.6591 - val_accuracy: 0.6406\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6454 - val_loss: 0.6586 - val_accuracy: 0.6406\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6706 - val_loss: 0.6580 - val_accuracy: 0.6406\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6427 - val_loss: 0.6574 - val_accuracy: 0.6406\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6734 - val_loss: 0.6569 - val_accuracy: 0.6406\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6650 - val_loss: 0.6563 - val_accuracy: 0.6406\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6375 - val_loss: 0.6558 - val_accuracy: 0.6406\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6542 - val_loss: 0.6552 - val_accuracy: 0.6406\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6702 - val_loss: 0.6547 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6446 - val_loss: 0.6542 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6386 - val_loss: 0.6536 - val_accuracy: 0.6406\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6217 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6772 - val_loss: 0.6526 - val_accuracy: 0.6406\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6771 - val_loss: 0.6521 - val_accuracy: 0.6406\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6346 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6397 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6557 - val_loss: 0.6506 - val_accuracy: 0.6406\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6372 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6376 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6693 - val_loss: 0.6491 - val_accuracy: 0.6406\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6377 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6386 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6740 - val_loss: 0.6476 - val_accuracy: 0.6406\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6359 - val_loss: 0.6471 - val_accuracy: 0.6406\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.6307 - val_loss: 0.6467 - val_accuracy: 0.6406\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6578 - val_loss: 0.6462 - val_accuracy: 0.6406\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6377 - val_loss: 0.6457 - val_accuracy: 0.6406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6563 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6370 - val_loss: 0.6447 - val_accuracy: 0.6406\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6457 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6194 - val_loss: 0.6438 - val_accuracy: 0.6406\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6370 - val_loss: 0.6433 - val_accuracy: 0.6406\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.6737 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6599 - val_loss: 0.6424 - val_accuracy: 0.6406\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6678 - val_loss: 0.6419 - val_accuracy: 0.6406\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.6670 - val_loss: 0.6415 - val_accuracy: 0.6406\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.6598 - val_loss: 0.6410 - val_accuracy: 0.6406\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6459 - val_loss: 0.6405 - val_accuracy: 0.6406\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6590 - val_loss: 0.6401 - val_accuracy: 0.6406\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6420 - val_loss: 0.6396 - val_accuracy: 0.6406\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6738 - val_loss: 0.6391 - val_accuracy: 0.6406\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6455 - val_loss: 0.6387 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6341 - val_loss: 0.6382 - val_accuracy: 0.6406\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6494 - val_loss: 0.6378 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6729 - val_loss: 0.6373 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6586 - val_loss: 0.6369 - val_accuracy: 0.6406\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6612 - val_loss: 0.6364 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6539 - val_loss: 0.6360 - val_accuracy: 0.6406\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6515 - val_loss: 0.6355 - val_accuracy: 0.6406\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6179 - val_loss: 0.6351 - val_accuracy: 0.6406\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6631 - val_loss: 0.6346 - val_accuracy: 0.6406\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6509 - val_loss: 0.6342 - val_accuracy: 0.6406\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6618 - val_loss: 0.6337 - val_accuracy: 0.6406\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6626 - val_loss: 0.6333 - val_accuracy: 0.6406\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6356 - val_loss: 0.6328 - val_accuracy: 0.6406\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6543 - val_loss: 0.6324 - val_accuracy: 0.6406\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.6707 - val_loss: 0.6320 - val_accuracy: 0.6406\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6870 - val_loss: 0.6315 - val_accuracy: 0.6406\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.6451 - val_loss: 0.6311 - val_accuracy: 0.6406\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6416 - val_loss: 0.6306 - val_accuracy: 0.6406\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.6789 - val_loss: 0.6302 - val_accuracy: 0.6406\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.6713 - val_loss: 0.6298 - val_accuracy: 0.6406\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6740 - val_loss: 0.6293 - val_accuracy: 0.6406\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6663 - val_loss: 0.6289 - val_accuracy: 0.6406\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6703 - val_loss: 0.6285 - val_accuracy: 0.6406\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.6889 - val_loss: 0.6280 - val_accuracy: 0.6406\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6585 - val_loss: 0.6276 - val_accuracy: 0.6406\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6468 - val_loss: 0.6272 - val_accuracy: 0.6406\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6404 - val_loss: 0.6267 - val_accuracy: 0.6406\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.6624 - val_loss: 0.6263 - val_accuracy: 0.6406\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6682 - val_loss: 0.6259 - val_accuracy: 0.6406\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6556 - val_loss: 0.6255 - val_accuracy: 0.6406\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6723 - val_loss: 0.6250 - val_accuracy: 0.6406\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6669 - val_loss: 0.6246 - val_accuracy: 0.6406\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.6609 - val_loss: 0.6242 - val_accuracy: 0.6406\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6487 - val_loss: 0.6238 - val_accuracy: 0.6406\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6239 - val_loss: 0.6233 - val_accuracy: 0.6406\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6804 - val_loss: 0.6229 - val_accuracy: 0.6406\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6583 - val_loss: 0.6225 - val_accuracy: 0.6406\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6485 - val_loss: 0.6221 - val_accuracy: 0.6406\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6512 - val_loss: 0.6217 - val_accuracy: 0.6406\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6359 - val_loss: 0.6213 - val_accuracy: 0.6406\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6905 - val_loss: 0.6208 - val_accuracy: 0.6406\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6595 - val_loss: 0.6204 - val_accuracy: 0.6406\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6504 - val_loss: 0.6200 - val_accuracy: 0.6406\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6692 - val_loss: 0.6196 - val_accuracy: 0.6406\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6639 - val_loss: 0.6192 - val_accuracy: 0.6406\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6598 - val_loss: 0.6188 - val_accuracy: 0.6406\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.6629 - val_loss: 0.6183 - val_accuracy: 0.6406\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6643 - val_loss: 0.6179 - val_accuracy: 0.6406\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6523 - val_loss: 0.6175 - val_accuracy: 0.6406\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5963 - accuracy: 0.6646 - val_loss: 0.6171 - val_accuracy: 0.6510\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6585 - val_loss: 0.6167 - val_accuracy: 0.6510\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.6624 - val_loss: 0.6163 - val_accuracy: 0.6510\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.6648 - val_loss: 0.6159 - val_accuracy: 0.6510\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.6435 - val_loss: 0.6155 - val_accuracy: 0.6510\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6205 - accuracy: 0.6224 - val_loss: 0.6151 - val_accuracy: 0.6510\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.6446 - val_loss: 0.6147 - val_accuracy: 0.6510\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.6826 - val_loss: 0.6143 - val_accuracy: 0.6510\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6477 - val_loss: 0.6139 - val_accuracy: 0.6510\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6611 - val_loss: 0.6135 - val_accuracy: 0.6510\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5900 - accuracy: 0.6683 - val_loss: 0.6131 - val_accuracy: 0.6510\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.5824 - accuracy: 0.6688 - val_loss: 0.6127 - val_accuracy: 0.6510\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5959 - accuracy: 0.6495 - val_loss: 0.6123 - val_accuracy: 0.6510\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6009 - accuracy: 0.6395 - val_loss: 0.6119 - val_accuracy: 0.6510\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6087 - accuracy: 0.6336 - val_loss: 0.6115 - val_accuracy: 0.6510\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.6522 - val_loss: 0.6111 - val_accuracy: 0.6562\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5890 - accuracy: 0.6707 - val_loss: 0.6107 - val_accuracy: 0.6562\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.6561 - val_loss: 0.6103 - val_accuracy: 0.6562\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.5979 - val_loss: 0.6099 - val_accuracy: 0.6562\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.6598 - val_loss: 0.6095 - val_accuracy: 0.6562\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.6550 - val_loss: 0.6091 - val_accuracy: 0.6562\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.6518 - val_loss: 0.6087 - val_accuracy: 0.6562\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6657 - val_loss: 0.6083 - val_accuracy: 0.6562\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.6768 - val_loss: 0.6079 - val_accuracy: 0.6562\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.6604 - val_loss: 0.6075 - val_accuracy: 0.6562\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6415 - val_loss: 0.6071 - val_accuracy: 0.6615\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.6729 - val_loss: 0.6067 - val_accuracy: 0.6615\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.6704 - val_loss: 0.6063 - val_accuracy: 0.6615\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.6453 - val_loss: 0.6060 - val_accuracy: 0.6615\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.6486 - val_loss: 0.6056 - val_accuracy: 0.6615\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.6734 - val_loss: 0.6052 - val_accuracy: 0.6615\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.6845 - val_loss: 0.6048 - val_accuracy: 0.6615\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.6586 - val_loss: 0.6044 - val_accuracy: 0.6562\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.6707 - val_loss: 0.6040 - val_accuracy: 0.6562\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.6617 - val_loss: 0.6036 - val_accuracy: 0.6562\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6560 - val_loss: 0.6032 - val_accuracy: 0.6562\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6648 - val_loss: 0.6029 - val_accuracy: 0.6562\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6560 - val_loss: 0.6025 - val_accuracy: 0.6562\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.6492 - val_loss: 0.6021 - val_accuracy: 0.6562\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.6694 - val_loss: 0.6017 - val_accuracy: 0.6562\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6410 - val_loss: 0.6013 - val_accuracy: 0.6562\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6543 - val_loss: 0.6010 - val_accuracy: 0.6562\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6654 - val_loss: 0.6006 - val_accuracy: 0.6562\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6326 - val_loss: 0.6002 - val_accuracy: 0.6562\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6542 - val_loss: 0.5998 - val_accuracy: 0.6562\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.6772 - val_loss: 0.5994 - val_accuracy: 0.6562\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6888 - val_loss: 0.5991 - val_accuracy: 0.6562\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.6543 - val_loss: 0.5987 - val_accuracy: 0.6562\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6562 - val_loss: 0.5983 - val_accuracy: 0.6562\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6441 - val_loss: 0.5979 - val_accuracy: 0.6562\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.6786 - val_loss: 0.5976 - val_accuracy: 0.6562\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.6685 - val_loss: 0.5972 - val_accuracy: 0.6562\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.6667 - val_loss: 0.5968 - val_accuracy: 0.6562\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.6542 - val_loss: 0.5964 - val_accuracy: 0.6562\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.6506 - val_loss: 0.5961 - val_accuracy: 0.6562\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.6495 - val_loss: 0.5957 - val_accuracy: 0.6562\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6640 - val_loss: 0.5953 - val_accuracy: 0.6562\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.6564 - val_loss: 0.5949 - val_accuracy: 0.6615\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.6619 - val_loss: 0.5946 - val_accuracy: 0.6615\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.6769 - val_loss: 0.5942 - val_accuracy: 0.6615\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6501 - val_loss: 0.5938 - val_accuracy: 0.6615\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.6581 - val_loss: 0.5935 - val_accuracy: 0.6615\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.6582 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6831 - val_loss: 0.5927 - val_accuracy: 0.6667\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6548 - val_loss: 0.5924 - val_accuracy: 0.6667\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6787 - val_loss: 0.5920 - val_accuracy: 0.6667\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.6518 - val_loss: 0.5916 - val_accuracy: 0.6667\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.6691 - val_loss: 0.5913 - val_accuracy: 0.6667\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.6866 - val_loss: 0.5909 - val_accuracy: 0.6667\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.6631 - val_loss: 0.5906 - val_accuracy: 0.6667\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6536 - val_loss: 0.5902 - val_accuracy: 0.6667\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.6693 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.6701 - val_loss: 0.5895 - val_accuracy: 0.6667\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.6880 - val_loss: 0.5891 - val_accuracy: 0.6667\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.6856 - val_loss: 0.5888 - val_accuracy: 0.6667\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.6838 - val_loss: 0.5884 - val_accuracy: 0.6667\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.6915 - val_loss: 0.5880 - val_accuracy: 0.6719\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.6613 - val_loss: 0.5877 - val_accuracy: 0.6771\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33020627],\n",
       "       [0.41211563],\n",
       "       [0.36642492],\n",
       "       [0.4168266 ],\n",
       "       [0.2899502 ],\n",
       "       [0.3376443 ],\n",
       "       [0.267144  ],\n",
       "       [0.34766337],\n",
       "       [0.56289   ],\n",
       "       [0.28474885]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.677\n",
      "roc-auc is 0.763\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e97e9e359a8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_hist_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "run_hist_1.history[\"loss\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24d82470b20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5702 - accuracy: 0.6806 - val_loss: 0.5873 - val_accuracy: 0.6771\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.6806 - val_loss: 0.5870 - val_accuracy: 0.6771\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5695 - accuracy: 0.6823 - val_loss: 0.5866 - val_accuracy: 0.6771\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5691 - accuracy: 0.6840 - val_loss: 0.5863 - val_accuracy: 0.6771\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6875 - val_loss: 0.5859 - val_accuracy: 0.6771\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6875 - val_loss: 0.5855 - val_accuracy: 0.6771\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6892 - val_loss: 0.5852 - val_accuracy: 0.6771\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.6892 - val_loss: 0.5848 - val_accuracy: 0.6771\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.6927 - val_loss: 0.5845 - val_accuracy: 0.6771\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6927 - val_loss: 0.5841 - val_accuracy: 0.6771\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.6927 - val_loss: 0.5838 - val_accuracy: 0.6771\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.6927 - val_loss: 0.5834 - val_accuracy: 0.6823\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.6927 - val_loss: 0.5831 - val_accuracy: 0.6875\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6927 - val_loss: 0.5827 - val_accuracy: 0.6875\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.6927 - val_loss: 0.5824 - val_accuracy: 0.6875\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5648 - accuracy: 0.6927 - val_loss: 0.5821 - val_accuracy: 0.6927\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5645 - accuracy: 0.6910 - val_loss: 0.5817 - val_accuracy: 0.6875\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.6927 - val_loss: 0.5814 - val_accuracy: 0.6823\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.6910 - val_loss: 0.5810 - val_accuracy: 0.6771\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.6944 - val_loss: 0.5807 - val_accuracy: 0.6771\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.6927 - val_loss: 0.5803 - val_accuracy: 0.6771\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.6962 - val_loss: 0.5800 - val_accuracy: 0.6771\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.6962 - val_loss: 0.5796 - val_accuracy: 0.6771\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.6997 - val_loss: 0.5793 - val_accuracy: 0.6771\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.6997 - val_loss: 0.5790 - val_accuracy: 0.6771\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7014 - val_loss: 0.5786 - val_accuracy: 0.6771\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7014 - val_loss: 0.5783 - val_accuracy: 0.6771\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7014 - val_loss: 0.5779 - val_accuracy: 0.6771\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7014 - val_loss: 0.5776 - val_accuracy: 0.6823\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.6997 - val_loss: 0.5773 - val_accuracy: 0.6823\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.6997 - val_loss: 0.5769 - val_accuracy: 0.6823\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7014 - val_loss: 0.5766 - val_accuracy: 0.6823\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.6997 - val_loss: 0.5763 - val_accuracy: 0.6823\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.6997 - val_loss: 0.5759 - val_accuracy: 0.6823\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.6997 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.6997 - val_loss: 0.5753 - val_accuracy: 0.6927\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.6997 - val_loss: 0.5749 - val_accuracy: 0.6927\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.6997 - val_loss: 0.5746 - val_accuracy: 0.6927\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.6997 - val_loss: 0.5743 - val_accuracy: 0.6979\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.7014 - val_loss: 0.5739 - val_accuracy: 0.6979\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5561 - accuracy: 0.7014 - val_loss: 0.5736 - val_accuracy: 0.6979\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7014 - val_loss: 0.5733 - val_accuracy: 0.6979\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7031 - val_loss: 0.5730 - val_accuracy: 0.7031\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7031 - val_loss: 0.5726 - val_accuracy: 0.7031\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7014 - val_loss: 0.5723 - val_accuracy: 0.7031\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.6997 - val_loss: 0.5720 - val_accuracy: 0.7083\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7014 - val_loss: 0.5717 - val_accuracy: 0.7135\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7031 - val_loss: 0.5713 - val_accuracy: 0.7135\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7031 - val_loss: 0.5710 - val_accuracy: 0.7135\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7031 - val_loss: 0.5707 - val_accuracy: 0.7135\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7031 - val_loss: 0.5704 - val_accuracy: 0.7135\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7049 - val_loss: 0.5701 - val_accuracy: 0.7135\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7014 - val_loss: 0.5697 - val_accuracy: 0.7135\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7014 - val_loss: 0.5694 - val_accuracy: 0.7135\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7031 - val_loss: 0.5691 - val_accuracy: 0.7135\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7031 - val_loss: 0.5688 - val_accuracy: 0.7135\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7031 - val_loss: 0.5685 - val_accuracy: 0.7135\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7031 - val_loss: 0.5681 - val_accuracy: 0.7135\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7031 - val_loss: 0.5678 - val_accuracy: 0.7135\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7031 - val_loss: 0.5675 - val_accuracy: 0.7135\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7014 - val_loss: 0.5672 - val_accuracy: 0.7135\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7014 - val_loss: 0.5669 - val_accuracy: 0.7135\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7014 - val_loss: 0.5666 - val_accuracy: 0.7135\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7014 - val_loss: 0.5663 - val_accuracy: 0.7188\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7014 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7014 - val_loss: 0.5656 - val_accuracy: 0.7240\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7014 - val_loss: 0.5653 - val_accuracy: 0.7240\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7014 - val_loss: 0.5650 - val_accuracy: 0.7240\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7031 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7031 - val_loss: 0.5644 - val_accuracy: 0.7240\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7031 - val_loss: 0.5641 - val_accuracy: 0.7240\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7031 - val_loss: 0.5638 - val_accuracy: 0.7240\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7014 - val_loss: 0.5635 - val_accuracy: 0.7188\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7014 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7014 - val_loss: 0.5629 - val_accuracy: 0.7188\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7031 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7049 - val_loss: 0.5623 - val_accuracy: 0.7240\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7066 - val_loss: 0.5620 - val_accuracy: 0.7240\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7066 - val_loss: 0.5617 - val_accuracy: 0.7240\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7066 - val_loss: 0.5614 - val_accuracy: 0.7240\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7066 - val_loss: 0.5611 - val_accuracy: 0.7240\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7066 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7083 - val_loss: 0.5605 - val_accuracy: 0.7292\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7083 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7083 - val_loss: 0.5599 - val_accuracy: 0.7292\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7066 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7066 - val_loss: 0.5593 - val_accuracy: 0.7292\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7083 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7101 - val_loss: 0.5587 - val_accuracy: 0.7344\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7101 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7118 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7101 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7118 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7153 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7153 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7170 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7188 - val_loss: 0.5564 - val_accuracy: 0.7344\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7188 - val_loss: 0.5561 - val_accuracy: 0.7344\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7188 - val_loss: 0.5559 - val_accuracy: 0.7344\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7188 - val_loss: 0.5556 - val_accuracy: 0.7344\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7205 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7222 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7222 - val_loss: 0.5547 - val_accuracy: 0.7344\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7222 - val_loss: 0.5545 - val_accuracy: 0.7344\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7222 - val_loss: 0.5542 - val_accuracy: 0.7344\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7222 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7240 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7240 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7257 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7257 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7257 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7257 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7274 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7292 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7292 - val_loss: 0.5514 - val_accuracy: 0.7344\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7292 - val_loss: 0.5512 - val_accuracy: 0.7344\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7274 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7257 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7257 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7274 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7274 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7257 - val_loss: 0.5496 - val_accuracy: 0.7344\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7292 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7292 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7292 - val_loss: 0.5488 - val_accuracy: 0.7344\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7274 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7292 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7292 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7309 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7309 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7326 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7326 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7361 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7344 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7344 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7361 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7361 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7378 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7378 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7378 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7378 - val_loss: 0.5447 - val_accuracy: 0.7500\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7361 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7361 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7378 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7378 - val_loss: 0.5437 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7378 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7378 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7378 - val_loss: 0.5430 - val_accuracy: 0.7604\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7361 - val_loss: 0.5428 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7361 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7361 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7344 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7344 - val_loss: 0.5418 - val_accuracy: 0.7604\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7344 - val_loss: 0.5416 - val_accuracy: 0.7604\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7344 - val_loss: 0.5413 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7361 - val_loss: 0.5411 - val_accuracy: 0.7604\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7361 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7361 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7378 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.7396 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7378 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7378 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7378 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7378 - val_loss: 0.5393 - val_accuracy: 0.7552\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7378 - val_loss: 0.5390 - val_accuracy: 0.7552\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7396 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7378 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7396 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7413 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7413 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7413 - val_loss: 0.5377 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7413 - val_loss: 0.5375 - val_accuracy: 0.7604\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7413 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7413 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7413 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7378 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7396 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7396 - val_loss: 0.5361 - val_accuracy: 0.7604\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7396 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7396 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7396 - val_loss: 0.5355 - val_accuracy: 0.7604\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7396 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7396 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7396 - val_loss: 0.5349 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7396 - val_loss: 0.5346 - val_accuracy: 0.7656\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7413 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7413 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7413 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7413 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7431 - val_loss: 0.5336 - val_accuracy: 0.7656\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7448 - val_loss: 0.5334 - val_accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7448 - val_loss: 0.5332 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7448 - val_loss: 0.5330 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7448 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7448 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7448 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7465 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7448 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7465 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7465 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7448 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7448 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7448 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7431 - val_loss: 0.5308 - val_accuracy: 0.7604\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7431 - val_loss: 0.5306 - val_accuracy: 0.7604\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7431 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7431 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7431 - val_loss: 0.5300 - val_accuracy: 0.7604\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7431 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7448 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7448 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7448 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7448 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7448 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7448 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7448 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7483 - val_loss: 0.5283 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7465 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7483 - val_loss: 0.5279 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7465 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7517 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7535 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7517 - val_loss: 0.5272 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7517 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7535 - val_loss: 0.5268 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7535 - val_loss: 0.5267 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7535 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7535 - val_loss: 0.5263 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7535 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7535 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7535 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7535 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7535 - val_loss: 0.5252 - val_accuracy: 0.7500\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7535 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.7535 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7535 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7535 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7552 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7535 - val_loss: 0.5242 - val_accuracy: 0.7500\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7552 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.5239 - val_accuracy: 0.7500\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7569 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7569 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7569 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7569 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7569 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7587 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7569 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7587 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7587 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7604 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7622 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7622 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7622 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7639 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7639 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7639 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7639 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7639 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7639 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7639 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7639 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7639 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7622 - val_loss: 0.5186 - val_accuracy: 0.7448\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7622 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7639 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7622 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7622 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7622 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7622 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4960 - accuracy: 0.7622 - val_loss: 0.5173 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7622 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7622 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7622 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7639 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7656 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7656 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7656 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7656 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7656 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7656 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7639 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7639 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7639 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7639 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7639 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7639 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7639 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7639 - val_loss: 0.5144 - val_accuracy: 0.7396\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7396\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7639 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7656 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7656 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7656 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7656 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7656 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7656 - val_loss: 0.5133 - val_accuracy: 0.7292\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7656 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7656 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7656 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7656 - val_loss: 0.5127 - val_accuracy: 0.7292\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7292\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7292\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7292\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7292\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7656 - val_loss: 0.5121 - val_accuracy: 0.7292\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7656 - val_loss: 0.5120 - val_accuracy: 0.7292\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7656 - val_loss: 0.5119 - val_accuracy: 0.7292\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7656 - val_loss: 0.5118 - val_accuracy: 0.7292\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7656 - val_loss: 0.5116 - val_accuracy: 0.7292\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7656 - val_loss: 0.5115 - val_accuracy: 0.7292\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7656 - val_loss: 0.5114 - val_accuracy: 0.7292\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5113 - val_accuracy: 0.7292\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7656 - val_loss: 0.5112 - val_accuracy: 0.7292\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7656 - val_loss: 0.5111 - val_accuracy: 0.7292\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7656 - val_loss: 0.5110 - val_accuracy: 0.7292\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7656 - val_loss: 0.5109 - val_accuracy: 0.7292\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7656 - val_loss: 0.5108 - val_accuracy: 0.7292\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5106 - val_accuracy: 0.7292\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7656 - val_loss: 0.5105 - val_accuracy: 0.7292\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5104 - val_accuracy: 0.7292\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.5103 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7674 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7674 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7656 - val_loss: 0.5097 - val_accuracy: 0.7344\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7674 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5095 - val_accuracy: 0.7344\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7674 - val_loss: 0.5093 - val_accuracy: 0.7344\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7344\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5091 - val_accuracy: 0.7344\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7674 - val_loss: 0.5090 - val_accuracy: 0.7344\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.5089 - val_accuracy: 0.7344\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7674 - val_loss: 0.5088 - val_accuracy: 0.7344\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7674 - val_loss: 0.5087 - val_accuracy: 0.7344\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7344\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7674 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7674 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7674 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7674 - val_loss: 0.5080 - val_accuracy: 0.7344\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.5079 - val_accuracy: 0.7396\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7674 - val_loss: 0.5078 - val_accuracy: 0.7396\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.5077 - val_accuracy: 0.7396\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7674 - val_loss: 0.5076 - val_accuracy: 0.7396\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7674 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7674 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7674 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7674 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7674 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7674 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7674 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7674 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7708 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7691 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7691 - val_loss: 0.5050 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7691 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7691 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7396\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7708 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7674 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7674 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7674 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7691 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7691 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7691 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.5018 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7448\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7448\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7448\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.5010 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7674 - val_loss: 0.5009 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.5007 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.5007 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7656 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.5003 - val_accuracy: 0.7448\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7448\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7656 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7656 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7448\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7448\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7396\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7396\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7344\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7344\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7344\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7344\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7344\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7344\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7344\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7344\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7344\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7344\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7344\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7344\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7344\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7344\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7344\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7344\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7344\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7344\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7344\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7344\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7344\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7344\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7344\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7344\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7344\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7639 - val_loss: 0.4981 - val_accuracy: 0.7344\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7344\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7344\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7344\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7344\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7396\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7639 - val_loss: 0.4977 - val_accuracy: 0.7396\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.4976 - val_accuracy: 0.7396\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.4976 - val_accuracy: 0.7396\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7639 - val_loss: 0.4975 - val_accuracy: 0.7396\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7639 - val_loss: 0.4975 - val_accuracy: 0.7396\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7639 - val_loss: 0.4975 - val_accuracy: 0.7396\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7639 - val_loss: 0.4974 - val_accuracy: 0.7396\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7396\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7639 - val_loss: 0.4973 - val_accuracy: 0.7396\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7639 - val_loss: 0.4973 - val_accuracy: 0.7396\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7639 - val_loss: 0.4972 - val_accuracy: 0.7396\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7639 - val_loss: 0.4971 - val_accuracy: 0.7396\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7396\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7396\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7396\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7396\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7396\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7674 - val_loss: 0.4968 - val_accuracy: 0.7396\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7396\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7396\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7396\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7396\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7396\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7396\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7448\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4910 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7726 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24d82796a00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1500\n",
      "576/576 [==============================] - 0s 295us/step - loss: 0.6739 - accuracy: 0.5747 - val_loss: 0.6753 - val_accuracy: 0.5885\n",
      "Epoch 2/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6717 - accuracy: 0.5868 - val_loss: 0.6734 - val_accuracy: 0.6042\n",
      "Epoch 3/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6696 - accuracy: 0.5990 - val_loss: 0.6715 - val_accuracy: 0.6146\n",
      "Epoch 4/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6675 - accuracy: 0.6146 - val_loss: 0.6697 - val_accuracy: 0.6354\n",
      "Epoch 5/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6655 - accuracy: 0.6215 - val_loss: 0.6679 - val_accuracy: 0.6458\n",
      "Epoch 6/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6634 - accuracy: 0.6424 - val_loss: 0.6661 - val_accuracy: 0.6250\n",
      "Epoch 7/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6614 - accuracy: 0.6476 - val_loss: 0.6643 - val_accuracy: 0.6198\n",
      "Epoch 8/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6594 - accuracy: 0.6580 - val_loss: 0.6626 - val_accuracy: 0.6042\n",
      "Epoch 9/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6575 - accuracy: 0.6649 - val_loss: 0.6610 - val_accuracy: 0.6094\n",
      "Epoch 10/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6556 - accuracy: 0.6615 - val_loss: 0.6594 - val_accuracy: 0.6250\n",
      "Epoch 11/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6579 - val_accuracy: 0.6458\n",
      "Epoch 12/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6520 - accuracy: 0.6615 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 13/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6503 - accuracy: 0.6632 - val_loss: 0.6549 - val_accuracy: 0.6562\n",
      "Epoch 14/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6486 - accuracy: 0.6736 - val_loss: 0.6534 - val_accuracy: 0.6562\n",
      "Epoch 15/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6470 - accuracy: 0.6806 - val_loss: 0.6520 - val_accuracy: 0.6667\n",
      "Epoch 16/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6454 - accuracy: 0.6806 - val_loss: 0.6506 - val_accuracy: 0.6771\n",
      "Epoch 17/1500\n",
      "576/576 [==============================] - 0s 46us/step - loss: 0.6438 - accuracy: 0.6910 - val_loss: 0.6493 - val_accuracy: 0.6823\n",
      "Epoch 18/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6423 - accuracy: 0.6840 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
      "Epoch 19/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6409 - accuracy: 0.6806 - val_loss: 0.6467 - val_accuracy: 0.6615\n",
      "Epoch 20/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6394 - accuracy: 0.6771 - val_loss: 0.6454 - val_accuracy: 0.6719\n",
      "Epoch 21/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6380 - accuracy: 0.6875 - val_loss: 0.6442 - val_accuracy: 0.6719\n",
      "Epoch 22/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6366 - accuracy: 0.6840 - val_loss: 0.6430 - val_accuracy: 0.6875\n",
      "Epoch 23/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6352 - accuracy: 0.6858 - val_loss: 0.6418 - val_accuracy: 0.6927\n",
      "Epoch 24/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6339 - accuracy: 0.6840 - val_loss: 0.6407 - val_accuracy: 0.6927\n",
      "Epoch 25/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6327 - accuracy: 0.6840 - val_loss: 0.6396 - val_accuracy: 0.6979\n",
      "Epoch 26/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6314 - accuracy: 0.6823 - val_loss: 0.6385 - val_accuracy: 0.7031\n",
      "Epoch 27/1500\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6301 - accuracy: 0.6840 - val_loss: 0.6374 - val_accuracy: 0.7031\n",
      "Epoch 28/1500\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.6289 - accuracy: 0.6823 - val_loss: 0.6364 - val_accuracy: 0.7031\n",
      "Epoch 29/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6277 - accuracy: 0.6858 - val_loss: 0.6353 - val_accuracy: 0.6927\n",
      "Epoch 30/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6265 - accuracy: 0.6858 - val_loss: 0.6343 - val_accuracy: 0.6927\n",
      "Epoch 31/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6253 - accuracy: 0.6840 - val_loss: 0.6333 - val_accuracy: 0.6927\n",
      "Epoch 32/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.6242 - accuracy: 0.6840 - val_loss: 0.6324 - val_accuracy: 0.6927\n",
      "Epoch 33/1500\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.6231 - accuracy: 0.6840 - val_loss: 0.6314 - val_accuracy: 0.6875\n",
      "Epoch 34/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.6220 - accuracy: 0.6806 - val_loss: 0.6305 - val_accuracy: 0.6823\n",
      "Epoch 35/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6209 - accuracy: 0.6840 - val_loss: 0.6296 - val_accuracy: 0.6823\n",
      "Epoch 36/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6198 - accuracy: 0.6858 - val_loss: 0.6286 - val_accuracy: 0.6823\n",
      "Epoch 37/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6188 - accuracy: 0.6840 - val_loss: 0.6277 - val_accuracy: 0.6771\n",
      "Epoch 38/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6177 - accuracy: 0.6840 - val_loss: 0.6269 - val_accuracy: 0.6771\n",
      "Epoch 39/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6167 - accuracy: 0.6840 - val_loss: 0.6260 - val_accuracy: 0.6823\n",
      "Epoch 40/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6156 - accuracy: 0.6840 - val_loss: 0.6251 - val_accuracy: 0.6823\n",
      "Epoch 41/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6146 - accuracy: 0.6840 - val_loss: 0.6243 - val_accuracy: 0.6823\n",
      "Epoch 42/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6136 - accuracy: 0.6858 - val_loss: 0.6235 - val_accuracy: 0.6823\n",
      "Epoch 43/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6126 - accuracy: 0.6875 - val_loss: 0.6226 - val_accuracy: 0.6823\n",
      "Epoch 44/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6115 - accuracy: 0.6892 - val_loss: 0.6218 - val_accuracy: 0.6823\n",
      "Epoch 45/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.6105 - accuracy: 0.6892 - val_loss: 0.6210 - val_accuracy: 0.6823\n",
      "Epoch 46/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.6095 - accuracy: 0.6892 - val_loss: 0.6201 - val_accuracy: 0.6771\n",
      "Epoch 47/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.6085 - accuracy: 0.6892 - val_loss: 0.6193 - val_accuracy: 0.6771\n",
      "Epoch 48/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.6076 - accuracy: 0.6910 - val_loss: 0.6186 - val_accuracy: 0.6771\n",
      "Epoch 49/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.6066 - accuracy: 0.6910 - val_loss: 0.6178 - val_accuracy: 0.6719\n",
      "Epoch 50/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6057 - accuracy: 0.6910 - val_loss: 0.6170 - val_accuracy: 0.6719\n",
      "Epoch 51/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6047 - accuracy: 0.6892 - val_loss: 0.6163 - val_accuracy: 0.6719\n",
      "Epoch 52/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.6038 - accuracy: 0.6892 - val_loss: 0.6156 - val_accuracy: 0.6719\n",
      "Epoch 53/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.6028 - accuracy: 0.6892 - val_loss: 0.6148 - val_accuracy: 0.6719\n",
      "Epoch 54/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6019 - accuracy: 0.6892 - val_loss: 0.6141 - val_accuracy: 0.6667\n",
      "Epoch 55/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.6010 - accuracy: 0.6910 - val_loss: 0.6134 - val_accuracy: 0.6667\n",
      "Epoch 56/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.6001 - accuracy: 0.6892 - val_loss: 0.6127 - val_accuracy: 0.6719\n",
      "Epoch 57/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5992 - accuracy: 0.6910 - val_loss: 0.6120 - val_accuracy: 0.6719\n",
      "Epoch 58/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5983 - accuracy: 0.6910 - val_loss: 0.6113 - val_accuracy: 0.6719\n",
      "Epoch 59/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5974 - accuracy: 0.6927 - val_loss: 0.6106 - val_accuracy: 0.6719\n",
      "Epoch 60/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5966 - accuracy: 0.6927 - val_loss: 0.6099 - val_accuracy: 0.6719\n",
      "Epoch 61/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5957 - accuracy: 0.6927 - val_loss: 0.6092 - val_accuracy: 0.6667\n",
      "Epoch 62/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5948 - accuracy: 0.6927 - val_loss: 0.6086 - val_accuracy: 0.6667\n",
      "Epoch 63/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5940 - accuracy: 0.6927 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
      "Epoch 64/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5931 - accuracy: 0.6927 - val_loss: 0.6072 - val_accuracy: 0.6667\n",
      "Epoch 65/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5922 - accuracy: 0.6927 - val_loss: 0.6066 - val_accuracy: 0.6667\n",
      "Epoch 66/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5913 - accuracy: 0.6910 - val_loss: 0.6059 - val_accuracy: 0.6667\n",
      "Epoch 67/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5904 - accuracy: 0.6927 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
      "Epoch 68/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5895 - accuracy: 0.6927 - val_loss: 0.6047 - val_accuracy: 0.6719\n",
      "Epoch 69/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5886 - accuracy: 0.6927 - val_loss: 0.6040 - val_accuracy: 0.6719\n",
      "Epoch 70/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5877 - accuracy: 0.6910 - val_loss: 0.6034 - val_accuracy: 0.6719\n",
      "Epoch 71/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5868 - accuracy: 0.6910 - val_loss: 0.6027 - val_accuracy: 0.6719\n",
      "Epoch 72/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5859 - accuracy: 0.6910 - val_loss: 0.6021 - val_accuracy: 0.6719\n",
      "Epoch 73/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5849 - accuracy: 0.6910 - val_loss: 0.6014 - val_accuracy: 0.6719\n",
      "Epoch 74/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5840 - accuracy: 0.6910 - val_loss: 0.6008 - val_accuracy: 0.6719\n",
      "Epoch 75/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5831 - accuracy: 0.6892 - val_loss: 0.6001 - val_accuracy: 0.6719\n",
      "Epoch 76/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5822 - accuracy: 0.6910 - val_loss: 0.5994 - val_accuracy: 0.6719\n",
      "Epoch 77/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5813 - accuracy: 0.6910 - val_loss: 0.5988 - val_accuracy: 0.6719\n",
      "Epoch 78/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5804 - accuracy: 0.6910 - val_loss: 0.5981 - val_accuracy: 0.6719\n",
      "Epoch 79/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5795 - accuracy: 0.6910 - val_loss: 0.5975 - val_accuracy: 0.6719\n",
      "Epoch 80/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5787 - accuracy: 0.6910 - val_loss: 0.5969 - val_accuracy: 0.6719\n",
      "Epoch 81/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5778 - accuracy: 0.6927 - val_loss: 0.5963 - val_accuracy: 0.6719\n",
      "Epoch 82/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5769 - accuracy: 0.6927 - val_loss: 0.5956 - val_accuracy: 0.6719\n",
      "Epoch 83/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5760 - accuracy: 0.6927 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
      "Epoch 84/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5752 - accuracy: 0.6927 - val_loss: 0.5944 - val_accuracy: 0.6667\n",
      "Epoch 85/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5743 - accuracy: 0.6944 - val_loss: 0.5937 - val_accuracy: 0.6667\n",
      "Epoch 86/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5734 - accuracy: 0.6944 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
      "Epoch 87/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5725 - accuracy: 0.6962 - val_loss: 0.5925 - val_accuracy: 0.6667\n",
      "Epoch 88/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5716 - accuracy: 0.6962 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
      "Epoch 89/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5708 - accuracy: 0.6962 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
      "Epoch 90/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5699 - accuracy: 0.6997 - val_loss: 0.5906 - val_accuracy: 0.6667\n",
      "Epoch 91/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5690 - accuracy: 0.7014 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 92/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5681 - accuracy: 0.7031 - val_loss: 0.5893 - val_accuracy: 0.6667\n",
      "Epoch 93/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5673 - accuracy: 0.7031 - val_loss: 0.5886 - val_accuracy: 0.6667\n",
      "Epoch 94/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5664 - accuracy: 0.7031 - val_loss: 0.5880 - val_accuracy: 0.6667\n",
      "Epoch 95/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5655 - accuracy: 0.7031 - val_loss: 0.5874 - val_accuracy: 0.6667\n",
      "Epoch 96/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5647 - accuracy: 0.7014 - val_loss: 0.5867 - val_accuracy: 0.6667\n",
      "Epoch 97/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5638 - accuracy: 0.7014 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
      "Epoch 98/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5629 - accuracy: 0.7014 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
      "Epoch 99/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5621 - accuracy: 0.7031 - val_loss: 0.5849 - val_accuracy: 0.6667\n",
      "Epoch 100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5612 - accuracy: 0.7031 - val_loss: 0.5842 - val_accuracy: 0.6667\n",
      "Epoch 101/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5604 - accuracy: 0.7031 - val_loss: 0.5836 - val_accuracy: 0.6667\n",
      "Epoch 102/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5595 - accuracy: 0.7031 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
      "Epoch 103/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5587 - accuracy: 0.7031 - val_loss: 0.5824 - val_accuracy: 0.6667\n",
      "Epoch 104/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5578 - accuracy: 0.7031 - val_loss: 0.5818 - val_accuracy: 0.6667\n",
      "Epoch 105/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5569 - accuracy: 0.7031 - val_loss: 0.5811 - val_accuracy: 0.6667\n",
      "Epoch 106/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5560 - accuracy: 0.7031 - val_loss: 0.5805 - val_accuracy: 0.6667\n",
      "Epoch 107/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5552 - accuracy: 0.7049 - val_loss: 0.5799 - val_accuracy: 0.6719\n",
      "Epoch 108/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5543 - accuracy: 0.7049 - val_loss: 0.5793 - val_accuracy: 0.6771\n",
      "Epoch 109/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5534 - accuracy: 0.7049 - val_loss: 0.5787 - val_accuracy: 0.6771\n",
      "Epoch 110/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5525 - accuracy: 0.7049 - val_loss: 0.5781 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5516 - accuracy: 0.7066 - val_loss: 0.5775 - val_accuracy: 0.6771\n",
      "Epoch 112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5508 - accuracy: 0.7083 - val_loss: 0.5769 - val_accuracy: 0.6771\n",
      "Epoch 113/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5499 - accuracy: 0.7083 - val_loss: 0.5764 - val_accuracy: 0.6771\n",
      "Epoch 114/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5490 - accuracy: 0.7101 - val_loss: 0.5758 - val_accuracy: 0.6771\n",
      "Epoch 115/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5482 - accuracy: 0.7101 - val_loss: 0.5752 - val_accuracy: 0.6771\n",
      "Epoch 116/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5473 - accuracy: 0.7101 - val_loss: 0.5747 - val_accuracy: 0.6875\n",
      "Epoch 117/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5465 - accuracy: 0.7101 - val_loss: 0.5741 - val_accuracy: 0.6927\n",
      "Epoch 118/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5456 - accuracy: 0.7101 - val_loss: 0.5736 - val_accuracy: 0.6927\n",
      "Epoch 119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5448 - accuracy: 0.7101 - val_loss: 0.5730 - val_accuracy: 0.6927\n",
      "Epoch 120/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5439 - accuracy: 0.7101 - val_loss: 0.5725 - val_accuracy: 0.6875\n",
      "Epoch 121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5431 - accuracy: 0.7118 - val_loss: 0.5719 - val_accuracy: 0.6875\n",
      "Epoch 122/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5422 - accuracy: 0.7118 - val_loss: 0.5713 - val_accuracy: 0.6875\n",
      "Epoch 123/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5413 - accuracy: 0.7135 - val_loss: 0.5708 - val_accuracy: 0.6875\n",
      "Epoch 124/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5404 - accuracy: 0.7135 - val_loss: 0.5702 - val_accuracy: 0.6875\n",
      "Epoch 125/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5396 - accuracy: 0.7170 - val_loss: 0.5697 - val_accuracy: 0.6875\n",
      "Epoch 126/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5387 - accuracy: 0.7170 - val_loss: 0.5691 - val_accuracy: 0.6927\n",
      "Epoch 127/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5379 - accuracy: 0.7188 - val_loss: 0.5686 - val_accuracy: 0.6927\n",
      "Epoch 128/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5370 - accuracy: 0.7188 - val_loss: 0.5680 - val_accuracy: 0.6927\n",
      "Epoch 129/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5361 - accuracy: 0.7188 - val_loss: 0.5675 - val_accuracy: 0.6927\n",
      "Epoch 130/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5352 - accuracy: 0.7188 - val_loss: 0.5669 - val_accuracy: 0.6927\n",
      "Epoch 131/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5343 - accuracy: 0.7205 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
      "Epoch 132/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5334 - accuracy: 0.7188 - val_loss: 0.5659 - val_accuracy: 0.6875\n",
      "Epoch 133/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5325 - accuracy: 0.7257 - val_loss: 0.5653 - val_accuracy: 0.6875\n",
      "Epoch 134/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5316 - accuracy: 0.7240 - val_loss: 0.5648 - val_accuracy: 0.6875\n",
      "Epoch 135/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5306 - accuracy: 0.7240 - val_loss: 0.5642 - val_accuracy: 0.6927\n",
      "Epoch 136/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5297 - accuracy: 0.7257 - val_loss: 0.5637 - val_accuracy: 0.6927\n",
      "Epoch 137/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5288 - accuracy: 0.7274 - val_loss: 0.5632 - val_accuracy: 0.6927\n",
      "Epoch 138/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5279 - accuracy: 0.7274 - val_loss: 0.5626 - val_accuracy: 0.6927\n",
      "Epoch 139/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5269 - accuracy: 0.7274 - val_loss: 0.5621 - val_accuracy: 0.6927\n",
      "Epoch 140/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5260 - accuracy: 0.7292 - val_loss: 0.5616 - val_accuracy: 0.6927\n",
      "Epoch 141/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5251 - accuracy: 0.7292 - val_loss: 0.5611 - val_accuracy: 0.6979\n",
      "Epoch 142/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5242 - accuracy: 0.7309 - val_loss: 0.5606 - val_accuracy: 0.6979\n",
      "Epoch 143/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5233 - accuracy: 0.7326 - val_loss: 0.5601 - val_accuracy: 0.6979\n",
      "Epoch 144/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5225 - accuracy: 0.7344 - val_loss: 0.5597 - val_accuracy: 0.6927\n",
      "Epoch 145/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5216 - accuracy: 0.7344 - val_loss: 0.5592 - val_accuracy: 0.6927\n",
      "Epoch 146/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5207 - accuracy: 0.7361 - val_loss: 0.5587 - val_accuracy: 0.6927\n",
      "Epoch 147/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5199 - accuracy: 0.7378 - val_loss: 0.5582 - val_accuracy: 0.6927\n",
      "Epoch 148/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5190 - accuracy: 0.7396 - val_loss: 0.5577 - val_accuracy: 0.6979\n",
      "Epoch 149/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.5181 - accuracy: 0.7396 - val_loss: 0.5572 - val_accuracy: 0.6927\n",
      "Epoch 150/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5172 - accuracy: 0.7431 - val_loss: 0.5567 - val_accuracy: 0.7031\n",
      "Epoch 151/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5162 - accuracy: 0.7431 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
      "Epoch 152/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5153 - accuracy: 0.7465 - val_loss: 0.5558 - val_accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5553 - val_accuracy: 0.7135\n",
      "Epoch 154/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5135 - accuracy: 0.7465 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
      "Epoch 155/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5127 - accuracy: 0.7465 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
      "Epoch 156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5117 - accuracy: 0.7483 - val_loss: 0.5540 - val_accuracy: 0.7135\n",
      "Epoch 157/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5109 - accuracy: 0.7465 - val_loss: 0.5536 - val_accuracy: 0.7135\n",
      "Epoch 158/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5531 - val_accuracy: 0.7135\n",
      "Epoch 159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5091 - accuracy: 0.7500 - val_loss: 0.5527 - val_accuracy: 0.7135\n",
      "Epoch 160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5082 - accuracy: 0.7500 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
      "Epoch 161/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5074 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7135\n",
      "Epoch 162/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5065 - accuracy: 0.7517 - val_loss: 0.5515 - val_accuracy: 0.7135\n",
      "Epoch 163/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.5049 - accuracy: 0.7500 - val_loss: 0.5506 - val_accuracy: 0.7240\n",
      "Epoch 165/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5040 - accuracy: 0.7500 - val_loss: 0.5503 - val_accuracy: 0.7292\n",
      "Epoch 166/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 167/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.5025 - accuracy: 0.7517 - val_loss: 0.5495 - val_accuracy: 0.7344\n",
      "Epoch 168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.5017 - accuracy: 0.7517 - val_loss: 0.5491 - val_accuracy: 0.7344\n",
      "Epoch 169/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.5009 - accuracy: 0.7517 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 170/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5483 - val_accuracy: 0.7344\n",
      "Epoch 171/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4994 - accuracy: 0.7535 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 172/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4987 - accuracy: 0.7535 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
      "Epoch 173/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4981 - accuracy: 0.7535 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
      "Epoch 174/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4974 - accuracy: 0.7500 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
      "Epoch 175/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4968 - accuracy: 0.7500 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 176/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4961 - accuracy: 0.7500 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 177/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4954 - accuracy: 0.7500 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 179/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4940 - accuracy: 0.7517 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
      "Epoch 180/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4934 - accuracy: 0.7500 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
      "Epoch 181/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4927 - accuracy: 0.7517 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
      "Epoch 182/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4921 - accuracy: 0.7535 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
      "Epoch 183/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4914 - accuracy: 0.7517 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
      "Epoch 184/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4908 - accuracy: 0.7517 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 185/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4901 - accuracy: 0.7517 - val_loss: 0.5427 - val_accuracy: 0.7292\n",
      "Epoch 186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4895 - accuracy: 0.7517 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
      "Epoch 187/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4889 - accuracy: 0.7500 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
      "Epoch 188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4882 - accuracy: 0.7483 - val_loss: 0.5417 - val_accuracy: 0.7292\n",
      "Epoch 189/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4876 - accuracy: 0.7500 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4870 - accuracy: 0.7483 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4864 - accuracy: 0.7483 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 192/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4859 - accuracy: 0.7483 - val_loss: 0.5405 - val_accuracy: 0.7240\n",
      "Epoch 193/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4853 - accuracy: 0.7483 - val_loss: 0.5402 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4847 - accuracy: 0.7465 - val_loss: 0.5400 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4841 - accuracy: 0.7465 - val_loss: 0.5397 - val_accuracy: 0.7240\n",
      "Epoch 196/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4836 - accuracy: 0.7465 - val_loss: 0.5394 - val_accuracy: 0.7240\n",
      "Epoch 197/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4830 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 198/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4824 - accuracy: 0.7483 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 199/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4818 - accuracy: 0.7483 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 200/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4812 - accuracy: 0.7483 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 201/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4806 - accuracy: 0.7483 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 202/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4800 - accuracy: 0.7483 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4795 - accuracy: 0.7500 - val_loss: 0.5371 - val_accuracy: 0.7135\n",
      "Epoch 204/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.5368 - val_accuracy: 0.7135\n",
      "Epoch 205/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4784 - accuracy: 0.7500 - val_loss: 0.5365 - val_accuracy: 0.7135\n",
      "Epoch 206/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4778 - accuracy: 0.7500 - val_loss: 0.5361 - val_accuracy: 0.7135\n",
      "Epoch 207/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4773 - accuracy: 0.7500 - val_loss: 0.5358 - val_accuracy: 0.7083\n",
      "Epoch 208/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4767 - accuracy: 0.7500 - val_loss: 0.5355 - val_accuracy: 0.7083\n",
      "Epoch 209/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4762 - accuracy: 0.7517 - val_loss: 0.5352 - val_accuracy: 0.7083\n",
      "Epoch 210/1500\n",
      "576/576 [==============================] - 0s 39us/step - loss: 0.4757 - accuracy: 0.7535 - val_loss: 0.5349 - val_accuracy: 0.7083\n",
      "Epoch 211/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4752 - accuracy: 0.7535 - val_loss: 0.5346 - val_accuracy: 0.7083\n",
      "Epoch 212/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4746 - accuracy: 0.7517 - val_loss: 0.5343 - val_accuracy: 0.7083\n",
      "Epoch 213/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4741 - accuracy: 0.7517 - val_loss: 0.5340 - val_accuracy: 0.7083\n",
      "Epoch 214/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4736 - accuracy: 0.7517 - val_loss: 0.5337 - val_accuracy: 0.7083\n",
      "Epoch 215/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4731 - accuracy: 0.7517 - val_loss: 0.5334 - val_accuracy: 0.7083\n",
      "Epoch 216/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4726 - accuracy: 0.7552 - val_loss: 0.5331 - val_accuracy: 0.7083\n",
      "Epoch 217/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4721 - accuracy: 0.7552 - val_loss: 0.5329 - val_accuracy: 0.7083\n",
      "Epoch 218/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4716 - accuracy: 0.7552 - val_loss: 0.5326 - val_accuracy: 0.7083\n",
      "Epoch 219/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4712 - accuracy: 0.7569 - val_loss: 0.5323 - val_accuracy: 0.7083\n",
      "Epoch 220/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4707 - accuracy: 0.7569 - val_loss: 0.5321 - val_accuracy: 0.7083\n",
      "Epoch 221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4703 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7135\n",
      "Epoch 222/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4698 - accuracy: 0.7587 - val_loss: 0.5316 - val_accuracy: 0.7135\n",
      "Epoch 223/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4694 - accuracy: 0.7604 - val_loss: 0.5314 - val_accuracy: 0.7135\n",
      "Epoch 224/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4689 - accuracy: 0.7622 - val_loss: 0.5312 - val_accuracy: 0.7135\n",
      "Epoch 225/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5309 - val_accuracy: 0.7135\n",
      "Epoch 226/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4681 - accuracy: 0.7622 - val_loss: 0.5307 - val_accuracy: 0.7135\n",
      "Epoch 227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4678 - accuracy: 0.7622 - val_loss: 0.5305 - val_accuracy: 0.7135\n",
      "Epoch 228/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4674 - accuracy: 0.7622 - val_loss: 0.5303 - val_accuracy: 0.7135\n",
      "Epoch 229/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4670 - accuracy: 0.7622 - val_loss: 0.5301 - val_accuracy: 0.7135\n",
      "Epoch 230/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4666 - accuracy: 0.7604 - val_loss: 0.5299 - val_accuracy: 0.7135\n",
      "Epoch 231/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4663 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 232/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4659 - accuracy: 0.7604 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 233/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4655 - accuracy: 0.7604 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 234/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4652 - accuracy: 0.7604 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 235/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4649 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4646 - accuracy: 0.7604 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4642 - accuracy: 0.7604 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 238/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4639 - accuracy: 0.7587 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 239/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4636 - accuracy: 0.7587 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 240/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4633 - accuracy: 0.7604 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 241/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4630 - accuracy: 0.7587 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
      "Epoch 242/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4627 - accuracy: 0.7569 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 243/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4624 - accuracy: 0.7569 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 244/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4621 - accuracy: 0.7587 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 245/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4619 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 246/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4616 - accuracy: 0.7587 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 247/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4614 - accuracy: 0.7587 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 248/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4611 - accuracy: 0.7587 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 249/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4608 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 250/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4606 - accuracy: 0.7587 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 251/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4603 - accuracy: 0.7587 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 252/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4601 - accuracy: 0.7587 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 253/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4598 - accuracy: 0.7587 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 254/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4596 - accuracy: 0.7622 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 255/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4593 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 256/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4591 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 257/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4589 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 258/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4586 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 259/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4583 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 260/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4581 - accuracy: 0.7604 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 261/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4579 - accuracy: 0.7604 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 262/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4576 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 263/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4574 - accuracy: 0.7587 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 264/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4572 - accuracy: 0.7604 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 265/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4569 - accuracy: 0.7587 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 266/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4567 - accuracy: 0.7569 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 267/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4565 - accuracy: 0.7587 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
      "Epoch 268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4562 - accuracy: 0.7569 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 269/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4560 - accuracy: 0.7587 - val_loss: 0.5253 - val_accuracy: 0.7240\n",
      "Epoch 270/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4558 - accuracy: 0.7622 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 271/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4556 - accuracy: 0.7604 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4553 - accuracy: 0.7604 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
      "Epoch 273/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4551 - accuracy: 0.7622 - val_loss: 0.5249 - val_accuracy: 0.7135\n",
      "Epoch 274/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4549 - accuracy: 0.7622 - val_loss: 0.5248 - val_accuracy: 0.7135\n",
      "Epoch 275/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4547 - accuracy: 0.7639 - val_loss: 0.5247 - val_accuracy: 0.7135\n",
      "Epoch 276/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4545 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
      "Epoch 277/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4542 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
      "Epoch 278/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4540 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 279/1500\n",
      "576/576 [==============================] - 0s 99us/step - loss: 0.4538 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 280/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4536 - accuracy: 0.7622 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4534 - accuracy: 0.7604 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 282/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4532 - accuracy: 0.7604 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 283/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4530 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 284/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4528 - accuracy: 0.7622 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 285/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4526 - accuracy: 0.7604 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
      "Epoch 286/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4524 - accuracy: 0.7639 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 287/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4522 - accuracy: 0.7622 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 288/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4520 - accuracy: 0.7604 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 289/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4518 - accuracy: 0.7622 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 290/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4516 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 291/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4515 - accuracy: 0.7604 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 292/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4513 - accuracy: 0.7622 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 293/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4511 - accuracy: 0.7604 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 294/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4509 - accuracy: 0.7656 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 295/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4507 - accuracy: 0.7604 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 296/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4506 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 297/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4504 - accuracy: 0.7604 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 298/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4502 - accuracy: 0.7587 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 299/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4501 - accuracy: 0.7604 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 300/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4499 - accuracy: 0.7587 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 301/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4497 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 302/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4496 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 303/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4494 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 304/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4492 - accuracy: 0.7639 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 305/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4491 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 306/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4489 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 307/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4488 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 308/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4486 - accuracy: 0.7674 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 309/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4484 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 310/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 311/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4482 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 312/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4480 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 313/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4479 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 314/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 315/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4476 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 316/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4475 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 317/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4474 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 318/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 319/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4470 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 320/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 321/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4468 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 322/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 323/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 324/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 325/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 326/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 327/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4459 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 328/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4458 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 329/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4457 - accuracy: 0.7760 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 330/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 331/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 332/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 333/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
      "Epoch 334/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 335/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 336/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.7292\n",
      "Epoch 337/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 338/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 339/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7292\n",
      "Epoch 340/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 341/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 342/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 343/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 344/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.65 - 0s 35us/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 345/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 346/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 347/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 348/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 349/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 350/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 351/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 352/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 353/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 354/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 355/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 356/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 357/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 358/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4425 - accuracy: 0.7743 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 359/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 360/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 361/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 362/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 363/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 364/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 365/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4418 - accuracy: 0.7795 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 366/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 367/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 373/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 377/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 378/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 379/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 380/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 381/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 382/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.75 - 0s 35us/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 383/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.81 - 0s 33us/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 384/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 385/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 386/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 387/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4396 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 388/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 389/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 390/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 391/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 392/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 393/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 394/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 395/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 396/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 397/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 398/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 399/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 400/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 401/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 402/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 403/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 404/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 405/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 406/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 407/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 408/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 409/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 410/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 411/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 412/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 413/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 414/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 415/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 416/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 417/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 418/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 419/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 420/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 421/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 422/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 423/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 424/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 425/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 426/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 427/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 428/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 429/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.81 - 0s 35us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 430/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 431/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.81 - 0s 35us/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 432/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 433/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 434/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 435/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.90 - 0s 33us/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 436/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 437/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 438/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 439/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 440/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 441/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 442/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 443/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 444/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 445/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 446/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 447/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 451/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 452/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 453/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 454/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.78 - 0s 33us/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 455/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.81 - 0s 35us/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 456/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 457/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.68 - 0s 35us/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 458/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 459/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 460/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 465/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 466/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 467/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 468/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 469/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 470/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 471/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 472/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 473/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 474/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 475/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4332 - accuracy: 0.7778 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 476/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.75 - 0s 33us/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 477/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 478/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.75 - 0s 35us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4330 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 480/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 481/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 482/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 483/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 484/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4327 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 485/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 486/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 487/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4325 - accuracy: 0.7795 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "576/576 [==============================] - 0s 31us/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4324 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - accuracy: 0.7778 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 494/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 495/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4321 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 496/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 497/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4319 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 500/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4318 - accuracy: 0.7812 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 501/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4318 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 502/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 503/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 504/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4316 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 505/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 506/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 507/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7778 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 509/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4314 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 510/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 511/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4313 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 512/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4312 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 513/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4312 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 514/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 515/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 516/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 517/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 518/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 519/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.75 - 0s 36us/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 542/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 543/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 546/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.75 - 0s 35us/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 559/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 560/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 561/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 562/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.90 - 0s 35us/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 565/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 566/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.75 - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 603/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 604/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 605/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 606/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 607/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 608/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 609/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 610/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 611/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 612/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.75 - 0s 35us/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 613/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 614/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 615/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 616/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 617/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.75 - 0s 35us/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 618/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 619/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.71 - 0s 35us/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 620/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 621/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 624/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 625/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 626/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 639/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 640/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 641/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 642/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 643/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 644/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 645/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 646/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 647/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 648/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 649/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 650/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 651/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 652/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 653/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 654/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 655/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 656/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 657/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 658/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 659/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 660/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 661/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 662/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 663/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 664/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 665/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 666/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 667/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4253 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 692/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 696/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4247 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 697/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 698/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.81 - 0s 35us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4245 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 709/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 710/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 711/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 712/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 713/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 714/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 715/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 716/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4242 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 717/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 718/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 719/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4241 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 720/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 721/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 722/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 723/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 724/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 725/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 726/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 727/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 728/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 729/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 730/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4238 - accuracy: 0.7847 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 731/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 732/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7830 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 733/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 734/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7830 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 735/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 736/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 737/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 738/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4236 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 739/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 740/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 741/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4235 - accuracy: 0.7847 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 742/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 743/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 744/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 745/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 746/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 747/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 748/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 749/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 750/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7847 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 751/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7830 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 752/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4232 - accuracy: 0.7847 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 753/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4232 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 754/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4231 - accuracy: 0.7847 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 755/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 756/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 757/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4231 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 758/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7830 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 759/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 760/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 761/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4230 - accuracy: 0.7847 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 762/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 763/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 764/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 765/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.7847 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.7812 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4228 - accuracy: 0.7830 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4227 - accuracy: 0.7847 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 774/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
      "Epoch 775/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4227 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 776/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 777/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.7830 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 778/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 779/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 780/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4225 - accuracy: 0.7847 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 781/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 782/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 783/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4225 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 784/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5232 - val_accuracy: 0.7552\n",
      "Epoch 785/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 786/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 787/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 788/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 789/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 790/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
      "Epoch 791/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 792/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 793/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7830 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 794/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4222 - accuracy: 0.7847 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 795/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 796/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7847 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 797/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 798/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4221 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 799/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 800/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 801/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.71 - 0s 38us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 802/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 803/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 804/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 805/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.7830 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 806/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 807/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 808/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 809/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 810/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 811/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 812/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 813/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4217 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 814/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 815/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 816/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.7830 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 817/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 818/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.90 - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 819/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4216 - accuracy: 0.7847 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 820/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 821/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 822/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4215 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 823/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 824/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 825/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 826/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 827/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4214 - accuracy: 0.7830 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 828/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4214 - accuracy: 0.7812 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 829/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 830/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 831/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.7830 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 832/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4213 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 833/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7830 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 834/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 835/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 836/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 837/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 838/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 839/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4212 - accuracy: 0.7812 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 840/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7830 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 841/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 842/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 843/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 844/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4211 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 845/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 846/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 847/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 848/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 849/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4210 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 850/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 851/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 852/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 853/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4209 - accuracy: 0.7847 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 854/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 855/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 856/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4209 - accuracy: 0.7812 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 857/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4209 - accuracy: 0.7830 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 858/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 859/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 860/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.71 - 0s 35us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 861/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4208 - accuracy: 0.7830 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 862/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4208 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 863/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4207 - accuracy: 0.7812 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 864/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7865 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 865/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 866/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.75 - 0s 35us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 867/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 868/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 869/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4207 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 870/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 871/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 872/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 873/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 874/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 875/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.87 - 0s 33us/step - loss: 0.4206 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 876/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 877/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 878/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7830 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 879/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 880/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4205 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 881/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5256 - val_accuracy: 0.7552\n",
      "Epoch 882/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 883/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 884/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4204 - accuracy: 0.7830 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 885/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 886/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4204 - accuracy: 0.7812 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 887/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 888/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 889/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4203 - accuracy: 0.7812 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 890/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 891/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 892/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 893/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4203 - accuracy: 0.7830 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 894/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 895/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
      "Epoch 897/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 898/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7812 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 899/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 900/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4202 - accuracy: 0.7830 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 901/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 902/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 903/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 904/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 905/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 906/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4201 - accuracy: 0.7812 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 907/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 908/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 909/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7812 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
      "Epoch 910/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 911/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7812 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 912/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 913/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 914/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 915/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7812 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 916/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
      "Epoch 917/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 918/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7847 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 919/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 920/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 921/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 922/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 923/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 924/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
      "Epoch 925/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 926/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4198 - accuracy: 0.7812 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 927/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.78 - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 928/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 929/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 930/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4198 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 931/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
      "Epoch 932/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 933/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 934/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7830 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 935/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 936/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 937/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 938/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.81 - 0s 38us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 939/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4197 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
      "Epoch 940/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 941/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 942/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 943/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 944/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4196 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 945/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4196 - accuracy: 0.7830 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 946/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 947/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 948/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 949/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 950/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 951/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.87 - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 952/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 953/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 954/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 955/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4194 - accuracy: 0.7847 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4193 - accuracy: 0.7830 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 963/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 964/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 965/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 966/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 967/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.87 - 0s 33us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 968/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 969/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4193 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 970/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 971/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 972/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 973/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 974/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 975/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 976/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.84 - 0s 35us/step - loss: 0.4192 - accuracy: 0.7847 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 977/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 978/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 979/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 980/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4191 - accuracy: 0.7830 - val_loss: 0.5285 - val_accuracy: 0.7552\n",
      "Epoch 981/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 982/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 983/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 984/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 985/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4191 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 986/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 987/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 988/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5287 - val_accuracy: 0.7552\n",
      "Epoch 989/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 990/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 991/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 992/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 993/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7830 - val_loss: 0.5288 - val_accuracy: 0.7552\n",
      "Epoch 994/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 995/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 996/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5289 - val_accuracy: 0.7552\n",
      "Epoch 997/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 998/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7830 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 999/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7847 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1000/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 1001/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1002/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1003/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1004/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5291 - val_accuracy: 0.7552\n",
      "Epoch 1005/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1006/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1007/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1008/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7847 - val_loss: 0.5292 - val_accuracy: 0.7552\n",
      "Epoch 1009/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4188 - accuracy: 0.7830 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1010/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7847 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1011/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1012/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7812 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1013/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7552\n",
      "Epoch 1014/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7847 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1015/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1016/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.7830 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1017/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7552\n",
      "Epoch 1018/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4187 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1019/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1020/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1021/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1022/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 1023/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1024/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1025/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1026/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4186 - accuracy: 0.7847 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 1027/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1028/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 1029/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4186 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1030/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 1031/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1032/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1033/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1034/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4185 - accuracy: 0.7847 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1035/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.7830 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
      "Epoch 1036/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1037/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1038/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1039/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 1040/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7830 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1041/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1042/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1043/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 1044/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1045/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1046/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4183 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1047/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4184 - accuracy: 0.7830 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
      "Epoch 1049/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1050/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4183 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4182 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4182 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.71 - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "576/576 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.81 - 0s 43us/step - loss: 0.4180 - accuracy: 0.7847 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4180 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7865 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4179 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4179 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4179 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1098/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 1099/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1100/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4178 - accuracy: 0.7812 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1103/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 1104/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1105/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1106/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1107/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4178 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1108/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1109/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 1110/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 1111/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4177 - accuracy: 0.7812 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4176 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4177 - accuracy: 0.7830 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1118/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1120/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4175 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1124/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4176 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1125/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4176 - accuracy: 0.7795 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1132/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1133/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4175 - accuracy: 0.7795 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4174 - accuracy: 0.7778 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1148/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1149/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 1150/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1151/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1152/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1153/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1156/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4173 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
      "Epoch 1157/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1158/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4173 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1159/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1160/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1161/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1162/1500\n",
      "576/576 [==============================] - 0s 37us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 1163/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1164/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1165/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1166/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1167/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1168/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 1169/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1170/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1171/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1172/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1173/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1174/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1175/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 1176/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1177/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7795 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1178/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1179/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4170 - accuracy: 0.7812 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1180/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4171 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1181/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1183/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4170 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4169 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "576/576 [==============================] - 0s 35us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1198/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 1199/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1200/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7812 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1201/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1202/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1203/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4168 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1204/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1205/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1206/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1207/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1208/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1209/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 1210/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1211/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4167 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1212/1500\n",
      "576/576 [==============================] - 0s 33us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1213/1500\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1214/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1215/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1222/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4166 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4166 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4165 - accuracy: 0.7847 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4165 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1239/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1241/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1242/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 1243/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4164 - accuracy: 0.7830 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1244/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1245/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4164 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1246/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1247/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 1248/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1249/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1250/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1251/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1252/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1253/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1254/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4163 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1255/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1256/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 1257/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1258/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1259/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1260/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1261/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1262/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1263/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 1264/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1265/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1266/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4162 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1267/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1268/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1269/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1270/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1271/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 1272/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1273/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1274/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1275/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1276/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4161 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1277/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1278/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1279/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 1280/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1281/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1282/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1283/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1284/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 1285/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1286/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1287/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1288/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1289/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4160 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1290/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1291/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 1292/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1293/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1294/1500\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1295/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 1296/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 1297/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1298/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 1299/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1300/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1301/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 1302/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1303/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1304/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1305/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1306/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 1307/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1308/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1309/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1310/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1311/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1312/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 1313/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 1314/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1315/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1316/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1317/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5346 - val_accuracy: 0.7292\n",
      "Epoch 1318/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1319/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1320/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4157 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1321/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1322/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 1323/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1324/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1325/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1326/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 1327/1500\n",
      "576/576 [==============================] - 0s 52us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1328/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1329/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1330/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 1331/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1332/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - accuracy: 0.7830 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1333/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1334/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 1335/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1336/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1337/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1338/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 1339/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1340/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1341/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1342/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4155 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1343/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1344/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1345/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1346/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1347/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1348/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1349/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 1350/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1351/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4154 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1352/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1353/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 1354/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1355/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1356/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 1357/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1358/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1359/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1360/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 1361/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1362/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4153 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1363/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4153 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1364/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1365/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1366/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1367/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1368/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1369/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1370/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1371/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 1372/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1373/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1374/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1375/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 1376/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1377/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1378/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1379/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1380/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4152 - accuracy: 0.7847 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1381/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1382/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1383/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1384/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1385/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 1386/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1387/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1388/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1389/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1390/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1391/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1392/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1393/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 1394/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1395/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1396/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 1397/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4151 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1398/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1399/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1400/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1401/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1402/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 1403/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1404/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1405/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4150 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1406/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1407/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1408/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1409/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4149 - accuracy: 0.7830 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1410/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4149 - accuracy: 0.7830 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 1411/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1412/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1413/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1414/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1415/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1416/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4149 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1417/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 1418/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1419/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1420/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1421/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1422/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 1423/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1424/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1425/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1426/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1427/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4148 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1428/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1429/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 1430/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1431/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1432/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1433/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7830 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1434/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1435/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1436/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1437/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1438/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1439/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1440/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 1441/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1442/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4147 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1443/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1444/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 1445/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1446/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1447/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1448/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1449/1500\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1450/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1451/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1452/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1453/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1454/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 1455/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1456/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1457/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4146 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1458/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1459/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1460/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1461/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 1462/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1463/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 1464/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1465/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1466/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1467/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1468/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4145 - accuracy: 0.7847 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 1469/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1470/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4145 - accuracy: 0.7830 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1471/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1472/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1473/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7830 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 1474/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1475/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1476/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1477/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1478/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1479/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1480/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1481/1500\n",
      "576/576 [==============================] - 0s 50us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1482/1500\n",
      "576/576 [==============================] - 0s 47us/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 1483/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1484/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1485/1500\n",
      "576/576 [==============================] - 0s 49us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1486/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 1487/1500\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1488/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1489/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1490/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1491/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 1492/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1493/1500\n",
      "576/576 [==============================] - 0s 43us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1494/1500\n",
      "576/576 [==============================] - 0s 45us/step - loss: 0.4143 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1495/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1496/1500\n",
      "576/576 [==============================] - 0s 38us/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 1497/1500\n",
      "576/576 [==============================] - 0s 42us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 1498/1500\n",
      "576/576 [==============================] - 0s 40us/step - loss: 0.4142 - accuracy: 0.7830 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1499/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 1500/1500\n",
      "576/576 [==============================] - 0s 36us/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAF1CAYAAAAa1Xd+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3yU5Z3//9cnJ84HibRYUbECrggKSKHjAWLpgthtBelBJaVa24D77dZua0H7W1tXWxW0W+qua8lq7Vqo1i1KrdWFLiUCZRRRUVdcFRUqpSgGEVAgJLl+f1z3JDOTmWQmmUMyeT8fj/sxc5+vmUzu+cx1X9fnMuccIiIiIiLSrCjfBRARERER6WwUJIuIiIiIxFGQLCIiIiISR0GyiIiIiEgcBckiIiIiInEUJIuIiIiIxFGQLN2WmT1uZl/JcxkOmtnH81kGEZFCZmZzzGx1nsvwMzO7Pp9lkPSZ8iQLgJltB77mnPuffJclH8zscvzrPzeL56gBljnn7s7WOUSkawquD2cCQ5xzR/JcnIJmZg4Y4ZzblqXjX06Wv08kN1STLN2CmRVn+fgl2Ty+iBQuMxsGnAc44HM5PndBXbuy/XoK7f2S1ilIljaZ2dfNbJuZ7TWzR8zsY8FyM7OfmNk7Zva+mb1gZqODdRea2VYzO2BmfzGza5Icu8jM/snMdgTHuc/MBgTr/tvMvhG3/fNmdnHw/G/M7A9BuV4xsy9GbfcLM7vLzB4zsw+A8xOcu8bMvmZmpwE/A0JB84d9wfoeZna7mf3ZzN4Obpf1CtZVmNlOM1toZruBe83sGDN71Mz2mNl7wfOhwfY/wn8J/ltwjn8LljszGx48HxC8/j3B+/FPZlYUrLvczDYE5XnPzN40sxlRr+VyM3sjeL/fNLM56f+lRSRP5gJPAr8AYpqAmVkvM/txcE14P7gORK5D55rZRjPbZ2ZvBTWYTde2qGNcbmYbouadmf0/M3sNeC1Y9tPgGPvN7BkzOy9q+2Iz+56ZvR5cY54xsxPM7E4z+3FceX9nZt9K9CLN7Gwzezp4HU+b2dnB8kvMbHPctv9oZo8Ez9O6Fic4b9PrN7N1weLng2vxl4Llf2dmW4L3cqOZnRG1//bg+C8AH5hZiZldG/V+bDWzWcG2yb5PfmFmP4w6ZsLv1ai/z3wzey243t9pZhasG25mTwTv4btm9utE77VkiHNOkyaA7cCnEyz/FPAuMB7oAfwrsC5YNx14BhgIGHAacFyw7q/AecHzY4DxSc77VWAb8HGgL/AQ8Mtg3VzgT1HbjgL2BeXoA7wFXAGUBOV7Fzg92PYXwPvAOfgfgz0TnLsGf0sM4HJgQ9z6JcAjwCCgH/A74JZgXQVQDywKytMLKAdmA72D7f8LWJnofFHLHDA8eH4f8Ntg32HAq8CVUeU7CnwdKAauAnYF73sfYD9warDtcZH3QZMmTZ1/Cq6Bfw+cFfyffzRq3Z3BteP44H//7OCacyJwALgUKA2uP2ODfWKuNfHXt+C684fg2tYrWFYZHKME+A6wO3LdBL4LvAicGlxzzgy2nRhch4qC7Y4FPowuf9Q5BwHvAV8OznFpMF8eXDMP4JtARLZ/GrgkeJ7WtTjBuRO9/uFR8+OBd4BJwXv8Ffx3Yo9g/XZgC3BC1Pv1BeBj+O+XLwEf0Pz9F3O+YNkvgB8Gz5N+r0aV71H8d+uJwB7ggmDd/cD/F5y3J3Buvj+/hTzlvQCaOsdE8iD5HmBx1Hxf/EV8WPCP/irwychFMmq7PwPzgP5tnHcN8PdR86cGxy8JLoYfACcF634E/Dx4/iVgfdyxlgI/CJ7/ArivjXPXkCRIxn8RfACcErUsBLwZPK8A6kgQfEdtPxZ4L9H5opY5YHhwYT4CjIpaNw+oiSrftqh1vYN9h+CD5H34AL3FF4QmTZo67wScG1zzjg3m/w/4x+B5EXAIODPBftcBDyc5Zsy1JsH1zQGfaqNc70XOC7wCXJRku5eBvw2efwN4LMl2XwY2xS0LA5cHz5cB3w+ej8AHzb0zdC1O9Pqjg+S7gJvi9nkFmBI83w58tY33a0vkPYo/X7DsFzQHyUm/V6PKd27U+geBa4Pn9wHVwNB8f3a7w6TmFtKWjwE7IjPOuYNALXC8c+6PwL/hazreNrNqM+sfbDobuBDYEdwaCqVy/OB5Cb4m4gDwe+CSYN0lwPLg+UnApODW2L7gltYcfNAY8Va7XrE3GH+Bfibq+P8dLI/Y45w7HJkxs95mtjS4LbofWAcMtNTaQx8LlNHyvTg+an535Ilz7sPgaV/n3Af4Hw3zgb+a2e/N7G9SfqUikk9fAVY7594N5n9Fc5OLY/G1ha8n2O+EJMtTFXN9NLPvmNnLwW38fcCA4Pxtnes/8bXQBI+/TLJd/LUeYq9xv8LXLgNchr8L9yHtuBa3w0nAd+K+T04IyhwR/37NjWqesQ8YTfP71Zak36tR2+yOev4hPpAGWID/4bDJzF4ys6+meE5pBwXJ0pZd+AsIAGbWB3977C8Azrk7nHNnAacDI/G35XDOPe2cuwj4CLAS/0u4zePjby3VA28H8/cDlwZBdi9gbbD8LeAJ59zAqKmvc+6qqGOlk7olftt38TU4p0cdf4Bzrm8r+3wHXxM+yTnXH5gcLLcUyvMuviYh/r34S0qFd26Vc+5v8U0t/g/4j1T2E5H8CdrVfhGYYma7gza1/wicaWZn4q8Lh4FTEuz+VpLl4Gtee0fND0mwTdP1KGh/vDAoyzHOuYH45mqRa1dr51oGXBSU9zT89T6R+Gs9xF7jVgPHmtlYfLD8q2B5e67F6XoL+FHc90lv59z9ic5hZifhr7HfAMqD9+t/Se1aD218r7bGObfbOfd159zH8Hcb/92Cfi2SeQqSJVqpmfWMmkrwF6orzGysmfUAbgaecs5tN7NPmNkkMyvFX5QPAw1mVmY+L+UA59xRfHvZhiTnvB/4RzM72cz6Bsf/tXOuPlj/GP5icmOwvDFY/igw0sy+bGalwfSJoNNEe7wNDDWzMoDgPP8B/MTMPgJgZseb2fRWjtEPfzHfZ2aDgB8kOEfCnMjOuQb8D4kfmVm/4CL8bfwXUKvM7KNm9rngQnsEOEjy91tEOo+Z+P/VUfjmWWPxgeZ6YG5wHfo58C9m9jHzHehCwbV4OfBpM/ti0JGsPAgwwd/6vzi4uzUcuLKNcvTDV07sAUrM7PtA/6j1dwM3mdkI884ws3IA59xOfPvhXwIrnHOHkpzjMfw1+7KgvF8KXvejwXHqgd8At+HbHv8hWN6ea3Fb4q/F/wHMD77PzMz6mNlnzKxfkv374APhPUF5rsDXJEcfv+n7JIGk36ttFdzMvmBBh3B8kxiHrvdZoyBZoj2GD/Ii0w3OuTXA9cAKfGe8U2hu/tAff3F5D3/rqBa4PVj3ZWB70OxgPs234+L9HH9xXQe8iQ+0/yGy0vl8oQ8Bn6a5ZoGgKca0oCy78LemIh032uOPwEvAbjOL3PZciO9Q82TwOv4HX1OczBJ8bfe7+J7q/x23/qfA5833Vr4jwf7/gP+x8QawAf96f55C2Yvwtdi7gL3AFHwnIBHp3L4C3Ouc+3NQQ7jbObcb34xtTlBRcQ2+09zT+P/vRfg+IH/GN2n7TrB8C75DHcBP8O1038Y3h1hO61YBj+P7mOzAX4ejmxf8C/5H/Gp8pcc9+GtdxH8CY0je1ALnXC3wd0F5a/HNBv4uqpkJ+Gvep4H/iqoogfSvxW25AfjPoKnEF51zm/Gdov8N/322Dd+uONlr2Qr8GN+m+m38a/9T1CaJvk+i92/te7UtnwCeMrOD+M6MVzvn3kxxX0mTBhMRERGRdjOzyfi7XsOi7vaJdHmqSRYREZF2CZrbXQ3crQBZCo2CZBEREUlb0AdkH77D8JI8F0ck49TcQkREREQkjmqSRURERETiKEgWEREREYlTku8CxDv22GPdsGHD8l0MEZF2eeaZZ951zg1ue8vCoeu2iHRVrV2zO12QPGzYMDZv3pzvYoiItIuZxQ+9W/B03RaRrqq1a7aaW4iIiIiIxFGQLCIiIiISR0GyiIiIiEicTtcmWaQ7OXr0KDt37uTw4cP5LoqkqWfPngwdOpTS0tJ8F0VERLJAQbJIHu3cuZN+/foxbNgwzCzfxZEUOeeora1l586dnHzyyfkujoiIZIGaW4jk0eHDhykvL1eA3MWYGeXl5boDICJSwBQki+SZAuSuSX83EZHCpiBZpBurra1l7NixjB07liFDhnD88cc3zdfV1aV0jCuuuIJXXnkl5XPefffdfOtb32pvkUVERHJCbZJFurHy8nK2bNkCwA033EDfvn255pprYrZxzuGco6go8W/qe++9N+vlFBERyTXVJIt0NeEw3HKLf8ySbdu2MXr0aObPn8/48eP561//SlVVFRMmTOD000/nxhtvbNr23HPPZcuWLdTX1zNw4ECuvfZazjzzTEKhEO+8807K51y2bBljxoxh9OjRfO973wOgvr6eL3/5y03L77jjDgB+8pOfMGrUKM4880wqKysz++JFREQokJrkcBhqaqCiAkKhfJdGJIvCYZg6FerqoKwM1qzJ2od+69at3HvvvfzsZz8D4NZbb2XQoEHU19dz/vnn8/nPf55Ro0bF7PP+++8zZcoUbr31Vr797W/z85//nGuvvbbNc+3cuZN/+qd/YvPmzQwYMIBPf/rTPProowwePJh3332XF198EYB9+/YBsHjxYnbs2EFZWVnTMhHJoIULYelSOHgQGhoSb2MGRUX+sVcv6NMHevaEsWNhwQJ/bdIXtHRhXb4mORIzXH+9f8xi5ZpI/tXU+AC5ocE/1tRk7VSnnHIKn/jEJ5rm77//fsaPH8/48eN5+eWX2bp1a4t9evXqxYwZMwA466yz2L59e0rneuqpp/jUpz7FscceS2lpKZdddhnr1q1j+PDhvPLKK1x99dWsWrWKAQMGAHD66adTWVnJ8uXLladYJNMWLoTFi+H995MHyADO+fX19XDgAOzeDdu3w8qVMGUKVFfrC1q6tC4fJNfUQN0R52OGIy6bMYNI/lVU+Brk4mL/WFGRtVP16dOn6flrr73GT3/6U/74xz/ywgsvcMEFFyRMf1ZWVtb0vLi4mPr6+pTO5ZxLuLy8vJwXXniBc889lzvuuIN58+YBsGrVKubPn8+mTZuYMGECDa19kYtIeh56qOPHOHoUVqzI2Y96kWzo8kFyRfmLFDcewWiguPEIFeUv5rtIItkTCvkmFjfdlNWmFvH2799Pv3796N+/P3/9619ZtWpVRo//yU9+krVr11JbW0t9fT0PPPAAU6ZMYc+ePTjn+MIXvsA///M/8+yzz9LQ0MDOnTv51Kc+xW233caePXv48MMPM1oekW6nuhqOO87/AN+2LTPHXL26uSa6oQFuvx3Ky32zjGOOgcpKmDULRo3yNc/jxvnlJ5/sy5Mt2e7XEQ7DVVf5aeFCGDYM+vf3r/300xO/tvgy5aDvSU6Fw/5v3Lu3/4wVFUGPHv4z0Il1/TbJzz2HMQIAC+ZhTD5LJJJdoVDO2/aNHz+eUaNGMXr0aD7+8Y9zzjnndOh499xzD7/5zW+a5jdv3syNN95IRUUFzjk++9nP8pnPfIZnn32WK6+8EuccZsaiRYuor6/nsssu48CBAzQ2NrJw4UL69evX0Zco0n1VV0Nwlyar9u5tfv7hh7B8efP8yy83P9+3r7k8VVWZLUO2+3WEw/4OX7IUmnv3tnxt8WVasgS+9a2c9D3JiXAYzjuvZdOdurrmz8CyZbkvVyoi6Z06y3TWWWe5dNw8f7sr5qgD54x6N3/mrrT2F8mnrVu35rsI0gGJ/n7AZtcJrqW5nNK9bksnMWeOc0VFzvnWxa1Pw4c37zdtWmr7dHQqLvbnOu0054YMca5fP+d69nRuwADn+vd3buJEv27UKOeWLnVu40bnxo51rkcPv/3SpbGvd+NGv2308W++Ofn7s3GjX79xoz/WkCF+n0y9vlTf+498pPn1RcqTCQsWONenj3MlJf49y+Rry8fUq5d/TWlq7Zrd5WuSK8btp5iP0kAxjiLu/f1HmRvu2j+6REREsqqyMrYmty0XX9z8fPZs35Qi2xoaEp8n0h9i06bmZfE14bt3x9bYhsMwebLvZBhRVJS8X0d07a5Z7H6Z0tiY2nbvvONfS2mp3ycTtcuRzpkR2Xh9uXboUPNrWrQoI4fs8m2SQ7WP8lX7BdAIGEePqvOeiIhIqx5/vO1tSkvhIx/x6dyig46qKp8e7rTTfHvboUN9wNkZrVjhH2tqWgaC48YlDzSjMwl1lgDy6NHMdYLMROfMziqDr62TfqrTUFHBuKLn8S/F0UgR5ftez3epRERE2m/hQp972Kx5KirygevYsb4d8ZQpcMIJftt0j91afvHiYti40Qdjb7+duFauqgq2boU334S33oING3x5i4v948aNPpDOt/Xr/fu0b1/LQH7TJt+JMPI+RnI+Fxf7tHWdNWtOY6PvBNiW6mq/XXGxn6I/S5nqnNkZRd/16KAu39yCUIjas97GNjXgKMGop3bLW8Ap+S6ZiIhI+uJvhUc452s1n38+tnlBOreYkx0bfCA1ejTcdVf6t/IjmXeiBw6JHOPmm33zh/p6f44ePXyTiaNH/Xoz/9oij5l06BCsW+enRD78sOW6VJtB5Itz8P/+H4wZk/zvlKvOmO01YoT/TBw4kNnjFhXBzJmZO1zGjpRH5SOOwVEMOBzFlA+2fBdJREQkPeGwbwKQLIhtzeLFPvCITxlWXe1TrJ18sk+39u//nnj/m2/2QeyWLe1v6xoKwXXXxe5fVeUHGDl82B//yBHYv9/XUke6XDU2+scf/cgHyl1FpKyR2tlMHS8V9fVw9tl+hMP+/f0dhh49fM1xeTn8/d93rBw335xet7mbb/Y/gMA/Dh/e+vGvuMJ/Dm6+OfZ1m8G0abHHii7LtGmxxxo+PHZ/5zKaj7sgguTaPQ6jATCMBmr3ZPiXqIiISDaFw3DuuT5Iba9t2/wxIoFypDbx5ZebR8I7eLDlfq11YMuligof7HUFpaXNAztFnrcV5LbWbjvSlCbd13/kiK+Nra/3Pzz27vVTR5qKtGegqviBrlpr8hB9/Pi/eVmZ7xiabNCs2bNjj3XxxS33z+Bnues3twDKx56AWx1Vkzz2hHwXSaRLqKio4LrrrmP69OlNy5YsWcKrr77KvyercQL69u3LwYMH2bVrF9/85jdjch5HH/v2229nwoQJSY+zZMkSqqqq6N27NwAXXnghv/rVrxg4cGAHXhXccMMN9O3bl2uuuaZDxxHJmZqazNzmb2z0xwqFmjuttaWqqnOkhAqFfNnvuw+efNK3eT56tLkZRnRTjKKi2CYakXWR5ZluthFt6FB48EH/PNK8JPJ83z7/2LMnvPQS1Nb6dWb+fR43Du65xwe0R47AqafCjBl+u8hx7rvPdz57553svYaIsjIYMAA++AA+9jH49Kdh7tzMNLc55RT/GRw8GF57zb8no0bFHj/6bw7N68aMiT1WRCS39IoVPmCuqvLNK+L3z5RkueHyNbUn3+bN87c7a8qVfNTdPH972scQyYd850n+2c9+5i6//PKYZZMmTXLr1q1rdb8+ffq0eewpU6a4p59+utVtTjrpJLdnz562C5qmH/zgB+62227L+HHjKU+y8iRnxMaNzs2cmfxmdqr5dNsz9eiRuby72bRxo8+DW1zsH1sr84IF2Xu/oGX+5UyUOd7Spdkpu1n6ZSlwrV2zC6K5Rfnul2LbJO9+Kd9FEsmaTI5W+vnPf55HH32UI0eOALB9+3Z27drFueeey8GDB5k6dSrjx49nzJgx/Pa3v22x//bt2xk9ejQAhw4d4pJLLuGMM87gS1/6EocOHWra7qqrrmLChAmcfvrp/OAHPwDgjjvuYNeuXZx//vmcf/75AAwbNox3330XgH/5l39h9OjRjB49miVLljSd77TTTuPrX/86p59+OtOmTYs5T1sSHfODDz7gM5/5DGeeeSajR4/m17/+NQDXXnsto0aN4owzzlCNtGRPZIS2lStbruvRw6df27DB15addpqvlcsUM7jjjs5Ri9yWSE3lTTe1nSN40SL/vg0YACVxN8zLyny71ptvhjlzfHaLSEaL006DiRN92+6BA316uwUL/Ht/0km+FnTp0tRHAUynzPEiafYmTvT5nefPb9keNx0f+Yh/vT/6UdcfwS+XkkXP+ZraVZM88ylXFD3q3uSX0j6GSD6kW5PckYqJZC688EK3cuVK55xzt9xyi7vmmmucc84dPXrUvf/++8455/bs2eNOOeUU19jY6Jxrrkl+88033emnn+6cc+7HP/6xu+KKK5xzzj3//POuuLi4qSa5trbWOedcfX29mzJlinv++eedcy1rkiPzmzdvdqNHj3YHDx50Bw4ccKNGjXLPPvuse/PNN11xcbF77rnnnHPOfeELX3C//OUvW7ymRDXJyY75m9/8xn3ta19r2m7fvn2utrbWjRw5sun1vvfeewnfO9Ukqya5w26+OXmtX6LR4G6+2dcGRtcMlpS0v2axtRHnpHMZPlx/5yxo7ZpdEDXJFUP+jxLq8TXJRdz7p5EZqWUT6Wyi89tnIp88wKWXXsoDDzwAwAMPPMCll14K+B/Q3/ve9zjjjDP49Kc/zV/+8hfefvvtpMdZt24dlZWVAJxxxhmcccYZTesefPBBxo8fz7hx43jppZfYunVrq2XasGEDs2bNok+fPvTt25eLL76Y9evXA3DyySczduxYAM466yy2b9+e0utMdswxY8bwP//zPyxcuJD169czYMAA+vfvT8+ePfna177GQw891NRmWiTjkv0TFxcn7oCUqKPT+PHtO3dpaefosCepaW/+35IS/Z3bqSCC5NC4w3yVe2kada+xSKPuSUGK70CcievezJkzWbNmDc8++yyHDh1ifPCFu3z5cvbs2cMzzzzDli1b+OhHP8rhyHCwSViC3t1vvvkmt99+O2vWrOGFF17gM5/5TJvH8T/uE+vRo0fT8+LiYupTHA0r2TFHjhzJM888w5gxY7juuuu48cYbKSkpYdOmTcyePZuVK1dywQUXpHQOkaSmT28erMIMjjkGjjsu+fDOX/964lvikY5O8+f7ae1aeOopfys+nRRio0bBE0/otntXEmlGcuyxvjlItF69oF8/HxCXlPgviL59fVONdev0d26nggiSqa1lHM/RNOqes5QGoxHpajrSxC2Zvn37UlFRwVe/+tWmWmSA999/n4985COUlpaydu1aduzY0epxJk+ezPLlywH43//9X1544QUA9u/fT58+fRgwYABvv/02j0cNh9uvXz8OJEgmP3nyZFauXMmHH37IBx98wMMPP8x5553XodeZ7Ji7du2id+/eVFZWcs011/Dss89y8OBB3n//fS688EKWLFnClo6k5RKZPt0Hw9E/1Pbt84MpJDNuXPJ1oZAf8CN60I9Vq3xmi40bfcDUWrqxHj3g7rsVOHVFixbBnj3w2GOxIxyuWePzDh896qdIajj9EOqQgkgBR0UFtSWHsPrIqHuN1NZ2oYTkImmIHsgqUy699FIuvvjipmYXAHPmzOGzn/0sEyZMYOzYsfzN3/xNq8e46qqruOKKKzjjjDMYO3YsEydOBODMM89k3LhxnH766Xz84x/nnHPOadqnqqqKGTNmcNxxx7F27dqm5ePHj+fyyy9vOsbXvvY1xo0bl3LTCoAf/vCHTZ3zAHbu3JnwmKtWreK73/0uRUVFlJaWctddd3HgwAEuuugiDh8+jHOOn/zkJymfV6SFoKlQyoqKmlOHpSs6FVd5OTz3nF8+blzz80ynyZLcS5RyTTLOWrutmQ8TJkxwmzdvTnu/6sonmLd8ctP80gVvULVIQ1NL5/byyy9z2mmn5bsY0k6J/n5m9oxzLnly6ALU3ut2t1Fe7gd4SEVRka/pVQYCkZxo7ZpdGDXJwHOv9QueGeB4rub9fBZHRETEN7VINUBesMC3NVXNoEinUDBBMj17tD4vIiKSa088kfq2AwfCdddlrywikpbC6LgHjBsU6VTk4uZFRETyIBz2uRpToXRsIp1OwQTJtRyL0QAYRgO1HJvvIomkpLP1C5DU6O8mbaqpic0yUV7us0/MmeOD4uJiGDTIj+imLAQinU7BNLco592Yoan37U0td6pIPvXs2ZPa2lrKy8sT5hiWzsk5R21tLT179sx3UaSzCofh3//dj/wDPiD+3e+a09MsW5bf8olImwomSI7UJDtKAMdPNkxiZlg/zKVzGzp0KDt37mTPnj35LoqkqWfPngwdOjTfxZDOKByGc86JzYvc0AB33qkvJZEupGCC5Ioh/0cxY6nHAUZ9o1FTo+uRdG6lpaWcfPLJ+S6GiGRSTU1sgBwRNZCOiHR+KbVJNrMLzOwVM9tmZtcm2eaLZrbVzF4ys19FLW8wsy3B9EimCh4vNO4w3+bHwZzDoVH3REQkD5J9+cyYkdtyiEiHtFmTbGbFwJ3A3wI7gafN7BHn3NaobUYA1wHnOOfeM7OPRB3ikHNubIbL3VJtLQM50NTkQqPuiYhIXiQaLW/sWLVDFuliUqlJnghsc8694ZyrAx4ALorb5uvAnc659wCcc+9ktpgpKC+nnD1RnfdUkywiInmwb1/sfEmJ78QnIl1KKkHy8cBbUfM7g2XRRgIjzexPZvakmV0Qta6nmW0Ols9MdAIzqwq22dzuDky1tTzH+MgRgeZh6kVERHJmy5bY+fHj1UFGpAtKJUhO1GYhvkdCCTACqAAuBe42s4HBuhODMbEvA5aY2SktDuZctXNugnNuwuDBg1MufIyKith8lAC7d7fvWCIiIqkIh+GWW/xjZL5379htrrwy9+USkQ5LJbvFTuCEqPmhwK4E2zzpnDsKvGlmr+CD5qedc7sAnHNvmFkNMA54vaMFbyEUYty5r8M6iMTw/fe+AQzJ+KlEREQIh2HqVD+qXlkZLFkC3/oWHDnSvE1JCYwZk78yiki7pVKT/DQwwsxONrMy4BIgPkvFSuB8ADM7Ft/84g0zO8bMekQtPwfYSpbUDhrZNOoewI/XT2r6cS8iIpJRNQxENLMAACAASURBVDVw+LDPgXzoEHz72/6xsbF5G+f8diLS5bQZJDvn6oFvAKuAl4EHnXMvmdmNZva5YLNVQK2ZbQXWAt91ztUCpwGbzez5YPmt0VkxMq2CGopwEORKbnBF3Hdfts4mIiLd2r59sfmQP/ig5TZmvjmgiHQ5KQ0m4px7DHgsbtn3o5474NvBFL3NRiBn95lCQ97ks/yOlczK1SlFRKS7iu+gl8hHP6pOeyJdVEqDiXQZ48Yxg8iIRi6ySEREJH3Tp0NpqR8cpLraLwuH/RfLgAHw1lut7w8wZ052yygiWVMww1IDCdLAOaWBExGR9E2fDqtX++d798K8efD663D77c1tjvfvT77/wIFQVQWLFmW/rCKSFYVVk1xezm4+GrNIWeBERCRtTzzRctmSJbGd8lpz9Cic0iLjqXRilZU+GYlZ+lNREUyalO9XIJlWWEFybS1DyP1gfyIiUkDCYZ/WLV6iZcl88IGvfY4005BOrbISli/3iUrawznYtEmBcqEprCC5ooK5Jb+ilDoibZJ//7tGpYETEZHUZTJl24oVmTuWZM3jj7e9TSqefTYzx5HOobCC5FCI0N+V8xl+HywwjjaY0sCJiEjq4lO7dcTYsZk5jmTVjBmZOc748W1vI11HYXXcAxjScoQ9tUsWEZGUpZLaLV6PHr5h6qFDscsHDsxMmSSrli3zjw880L4mF2bwiU/AU09ltlySX4VVkwzK+SYiIh0ze3b6+9xxB6xZ44enjujRQwOJdCHLlkF9vb+JkO7U2KgAuRAVXk3yc88xhDNiFiWoXBYREUnNxIm+V1YyxcUwZowfNKSmhqY2fnPnaiARkS6s8GqSgXFEWs5rQBEREYkTDsMtt5C0V/dPfxo7v21b68drbGzu7BcKwV13+UkBclZ0JFVbW1P0uDHpmD7dt7Zp6/ilpb780jUUXpA8blzcgCKZ67UqIiJdXDgMU6fC9df7x/hAuboatm6NXTZhQux8cbGPdiLKytSsIkc6mqqtLZFxY9IJlCPjzqTS17O+3pdfgXLXUHhBcm1ti0WP/NYpDZyIiPga37o6H2XV1bVM95YoZVtFBSxd6ptdzJwJ69f7wUbmz/fT2rWqNc6RXFV6pZO5b/369I+vyruuofDaJFdUMLd4AdUNX6eRYsBodI777tM1TESk24uu8XUO/vxnX5sc+YIYPDh2+9JSv08o5IeZjqYvlZybMcPXxGZbOn03zzuveQTzVGUq5ZxkV+HVJIdChL5zNueyIWax0sCJiAgrVzbfq29s9DXEkWYX1dWxEdiZZ/oaYwXDncayZTBnjm/xkg2DBvmPRPzvodasWgXTpvk2x20pKfHlj6Sck86t8GqSAfbvZxB7810KERHpTBYuhNtvj13mnM9tfN998MYbsev27VOA3AktW9b5gsxVq/JdAsmGwqtJTmKvYmYR6SbM7AIze8XMtpnZtQnW/8TMtgTTq2a2L2pdQ9S6R3Jb8ixauBAWL/a1x4kk6qm1Y4ffT0S6pcIMkseNYwhvxyzasCF5th8RkUJhZsXAncAMYBRwqZmNit7GOfePzrmxzrmxwL8CD0WtPhRZ55z7XM4Knm2/+lXr6xsbE39JPPRQy2VdXHU19O+fXmq0jqQuW7jQj6vSGVK15VN1tS93e19zSYmyYuRaYQbJzz3HXO6jiAZ8rmSjsbE5v7uISAGbCGxzzr3hnKsDHgAuamX7S4H7c1KyfAmHYefOtrc7cKDlsosvznx58qi62qc4S/RSW9Pe1GWRCvy6uvT2a0t7UrXlU+R978hd7YYGpY/LtcIMkoEQT/I5CudOoYhIio4H3oqa3xksa8HMTgJOBv4YtbinmW02syfNbGayk5hZVbDd5j179mSi3NkTn+YtVSedBIsWZbQo+ZZOarNE0k1dlu2K+I6+nlzJZDmVPi53CjNIDobYm0Hkk6SR90Sk20jUxz7ZMAeXAL9xzkUPzXCic24CcBmwxMxOSbSjc67aOTfBOTdhcHzatM6mosIPh5au730v40XJt3RSmyWSbuqybFfEd/T15Eomy6n0cblTmEFybS2Y8TiRT5IBTr++RKQ72AmcEDU/FNiVZNtLiGtq4ZzbFTy+AdQAhVG9ED1CXq9ePh9y9LJ4Cxaklwesi6iq8inO+vVLb7/2pi5btMi/lWVl6e3XlvakasunyPs+aFD7j1FcrPRxuVaYQXJQa/AKI2MWP/dcfoojIpJDTwMjzOxkMyvDB8It2p6Z2anAMUA4atkxZtYjeH4scA6wNX7fLue+++DIEf/czA9J/c47cP75yfcZODA3ZcuDqirYv99nv0t1Onq0/cHZokX+7U/nfG1NtbVdJ0COqKry5W7va66vV4Cca4UZJIdC8NnPciqvxiyODKwkIlKonHP1wDeAVcDLwIPOuZfM7EYzi85WcSnwgHMuuinGacBmM3seWAvc6pzr2kFyZJCQCOfgpZf882T3wIuKYkfmE5FuqTCDZIAZM1jAbVhUhgvnlOFCRAqfc+4x59xI59wpzrkfBcu+75x7JGqbG5xz18btt9E5N8Y5d2bweE+uy55xNTUtcyM/9ZR/rKqCUaNa7MKECRpEREQKOEh+7jlCPMl5Gp5aRKT7qqhoOYZxdG+yq69uuc+VV2a1SJkQDsMJJ7TMHbxwIUyZAsccAyef7CvRw2EYOTJ22969Ux8nJf5cxcUwfXrq+86aBZMmdZ10bZ1ROAxXXeUn3RHPncIclhqaomENTy0i0o2FQrB+PVx7rR92+rLLYtO6RRq2LlniI8Crr+70jV3DYTj77JbL9+71OYkj9u3zuXkTOXSoedvWstwlOldjI6xe7QPl1oZjDodh8mTflhZg0yb/2Mnf3k4nHPa/9SK5pu+9F9au1c2OXCjcmuQhQxIsdBqeWkSku3nxRejZ03fYSxQRVlXB1q2+rXIXiODam/Y5kbbyGLd2rvXr2943EiBHdJW8xp1JTY3vOBlRV5fZz4AkV7hB8ty5UFSk4alFRLqzyFBnq1d3rSHaWpHJPoVt5TFu7Vznndf2viVx96u7Sl7jzqSiIjZbYVmZ+pXmSuEGyaEQfO5zGp5aRKQ7i6+6LICqzFAINm6EoUNjlw8a5HMST57sM9gNG+Zz827cCCNGxG7bq5fftq0BBROdq6gIpk1rvalFZN9162DmTJg4sWvlNe5MQiFfczx/vp/U1CJ3CrdNMsCMGYRWzuNcNrCOKU2L1XlPRKSbmD3b1yJHzxeAUAjeeqvt7SJefbXtbTJ1rvh9H364/ecWLxRSYJwPhR0kB6OHqPOeiEg3Fam6XLHCB8iqyhSRFBVucwtIWmW8fXtuiyEiIp1HdTUcdxz07QuVlfkujU/F1qtXbIq2VKaSkubyV1b6+ci6sjKfqq09adtakyidXHm5f0+TvY5Mnbu7q6yM/Zvmcxoxonv07yrsmuRAfOe9LVv8P7QqFEREClyk4x7A6tVUrzuVecubm98tX+4f8zXc78KFsWnb0tHQ4Mu/YQPs2BG7LjobAqSetq014TCcc44ftDDa3r3JU81l6tzdXWVl82e1M9i2Dc4913/2CrkZSGHXJAdp4OZyH9CI77zn3dP1x5ESEZG2xF3sVzzep8Umjz+eq8K01FYKtlT8+c+pb9tW2rbW1NS0DJDT0ZFzd3f5/Iwm09hY+KnoCjtInjsXiosJ8SRjeT5mVc+eeSqTiIjkRjgMzz4bs2j2jA9abDZjRq4K1FJbKdhSceKJqW/bVtq21lRU+Fvt7dWRc3d3+fyMJlNUVPip6Ao7SA6F4DvfAWAY2/NbFhERya34qs+ZM6laNoWlS/2Nxj59YM6c/DW1AJ+CbcGC9lXcFBf78m/f7h+jR98uLfVBTESqadtaEwrBn/7UMp3coEE+vVuy15GJc3d3y5b5v3FRJ4nahg8v/KYWAOY6cu8kCyZMmOA2b96cuQNedRX87GfMYgUrmQX4n8Fm/p+90P/AIpJbZvaMc25CvsuRSxm/bmdKOAznn++HKCsrU4JZEWmhtWt2J/lNkkVBhov4znvOaVAREZGCF6kI6mQVQiLS+RV+kByYy31Y08h7ngYVEREpYDU1Ps2Dc1BfDzU1LFzoU7/16OFHkZs0KbcjVSdLk9a7t1/X1UTS6UVSk3XV1yGpmz7dN/sw84+FnA6u8FPABRkuQjzJeXEj7+3VGCMiIoVr377mGuTGRhaunMTiTc2r//IXP20KlmU7LWhr6d4OHWpe19ZQ0Z1FdHa9iK74OiR106fHDmDpXGGngyv8muS5c5tausePvLd+feH++hER6fa2bImZfejFkUk3XbEi24VJLd1bJlLC5Upr71lXeh2SumRp/Ao1HVzhB8mhkP+Jg9oli4h0K7Nnx8xefN6eVDfNilTSvWUiJVyutPaedaXXIalLlsavUNPBFX6QDDBqFKB2ySIi3cqYMX6sZoCSEhbdcJgFC3zqt7IyOP54mDjRpy/LxQisraV769XLr+tKTRSqqmhKpxdJTdYVX4ekbtUqn84vki/brLDTwRV+m2SAceMA3y75TF5gC+OaVqldsohIgaqp8feBoel+8KJFobwGcIsWFVYAWVWVmx8Y0nl0p3zX3aMm+bnnmp4eoSxm1auv5rowIiKSE+XlsUFyeXl+yyMiXUr3CJKjnEpsVLx7d27T/4iISI48/njz86IiqK0lHIZbbvGdtisrfWuM4uKOp7FauNAfo7X0Z5WVvqlFv36FkyYtHIZZs3KfSk86h+h0cPmeSkr8/1gmdY/mFnPn+v/exkYWcBsruQj/+8A3qrnnHt0uEhEpKNXVsHJl83xxMeHyv2PqVD8An3PNlczQsTRW0andkqU/q6yE5cv98yNHCiNNWjgMkyf7FNSQu1R60jnEp4PLt4aG5v+xTA013z1qkqMyXIR4krE8H7O6ri4fhRIRkayJz082bhw1tWOoq/NfptEBckR701jFpztLlP4sulK7te26kpqa5gA5Ihep9KRzSJYOLt8S/a+1V0pBspldYGavmNk2M7s2yTZfNLOtZvaSmf0qavlXzOy1YPpKpgqetkGDmp4OY3vMquefV75kEZGCEp+f7MorqajwWS2Ki5uzMURrbxqr+HRnidKfzZjR9n5dTUVFc/KQiFyk0pPOIVk6uHxL9L/WXm0GyWZWDNwJzABGAZea2ai4bUYA1wHnOOdOB74VLB8E/ACYBEwEfmBmx2Su+O2jfMkiIgXu9ddbzIdCsGYN3HSTb1YxZ05zwNyRNFaR1G7DhydPf7ZsmT9fjx5+WOxCSJMWCsG6dTBzZm5T6UnnEJ8OLt+Ki/3/WKaaWgCYc671DcxCwA3OuenB/HUAzrlborZZDLzqnLs7bt9LgQrn3LxgfilQ45y7P9n5JkyY4DZv3tzOl9OKWbOa2qeF+STnsAFHcdPqmTPh4Yczf1oR6V7M7Bnn3IR8lyOXsnbd7oiPfhTeead5fvhweO21/JVHRDql1q7ZqTS3OB54K2p+Z7As2khgpJn9ycyeNLML0tgXM6sys81mtnnPnuQjInXIkCFNT32+5OeJHlRE+ZJFRApEdXVsgAxdv22DiORcKkFyoor0+OrnEmAEUAFcCtxtZgNT3BfnXLVzboJzbsLgwYNTKFI7zJ0b0wgtPl/yjh3ZOa2IiORYfO+xk07q+m0bRCTnUgmSdwInRM0PBXYl2Oa3zrmjzrk3gVfwQXMq++ZGVIYLaJkveccOdd4TESkI8b3Hvve9pqfReZIjKit9h74ePRLnWa2s9OOQxK+L5EaeNAkGDvSd2NrK5XrCCfquEekqUgmSnwZGmNnJZlYGXAI8ErfNSuB8ADM7Ft/84g1gFTDNzI4JOuxNC5blR1SGiwXcBsTmAIrkrRQRkcITDsPUqXD99f4xMqDI8uVw9KhPB7p8eWwwHFm/d2/sukhu5G3bfH7g99/3qeXasnOnr69RoCzS+bUZJDvn6oFv4IPbl4EHnXMvmdmNZva5YLNVQK2ZbQXWAt91ztU65/YCN+ED7aeBG4NleRfiSYb1iM1yETV6tYiIdFXxzS2C+ZoamvIk19X5+UQ5VaOXxa+PzHckx3F78zGLSG6llCfZOfeYc26kc+4U59yPgmXfd849Ejx3zrlvO+dGOefGOOceiNr358654cF0b3ZeRoqiOu8BnHjkVaKbSP/5z/p1LyLS5cU3twjmo/Mkl5X5+UQ5VaOXxa+PzHekH2B78zGLSG51j2GpI6KGpwYYxcusY0rT6ki+5PbkyRQRkU6iqsrnSX7oIR/NBsl7I3mSa2p8kBoKNV/vH3zQtxn+whdi86xGnj/+uA+QI/ORfoAPPeRb8r3yChw82HaTi6FD/bn0PSPS+bWZJznXsp5vc8oUn/0c5UsWkcxTnuROINL4uK7OVxmvWaOoVEQS6mie5MIS1XkvxJOc2X97zOrtsbMiItLVJGp8LCKSpu4XJMcpK4q9N7Zli9oli4h0aTU1ze0eioubGgAnSv8WUV3tU7nNmhW7fuFCGDwYevZMnNJtwAC/r4gUnu7VJjmBKwf/lk37vhuzbPFiNbkQEemSKith9erm+fp6oPUWGNXVMG9e8y6//z088QSsXNl2atD9+5v3DZo+i0iB6H41yXEZLqpev5Yhg47ELHvllVwWSEREMuZ3v4udD/KttdYCIz5j3NGjfn06ad7ijyEiXV/3C5LjhqemsZGRZdtjNunRI7dFEhGRDAiH4cCB2GVBvrVE6d8i4jPGlZb69emkeYs/hoh0fd2vuUVkeOogwwXAIN6L2eT55/21Vp2hRUS6kEQd9KqqIBQiRMv0b9GbANxzD3zsY7BgQWx6uJ//3MfeR47QQv/+cNttamohUoi6X5AMMRkuAIb03Bczr3zJIiJdUEWFrwauq/PzPXr4u4eB6MA3XlVV4kB30aLmnMgi0r10v+YWCcwd+EiLZVu35qEgIiLSfqGQryqeP99Pa9eqtkNE2q17BslxnfdCLyxl2JBDMct27MhlgUREJCNefBHeeAPGjWsKkMNhGDnSp2wrLobp0xPvWlkJ5eX+ceFC6NXLb19enjzN26RJfhulghMpPN2zuUXc8NQ0NjK25/+xnXFNm+zYoXbJIiJdSnQutyANXHhMFeec45vRgb/sr17tA+VVq5p3rayE5cv988hjxN69idO8TZoEmzb550oFJ1J4umdNcqTzXpQFJ/66xWZt5ccUEZFOJD4P24oV1NQ0B8jR1q+PnX/88fQP/+yzbW8jIl1X9wySoUXnvdCgVxg2LHYT5UsWEelC4vOwzZ5NRYVvZhHvvPNi52fMSP/w48e3vY2IdF3dN0hOYODA2PlgoCYREemiQiH4059gxAg/X1QE06bFNrUAWLYM5szx9Sdz5vg0cD17+u0HDYKlS1s2o3jqKZg40W/Tv3/ibUSk6+qebZIT2buXsrLYRdu2qV2yiEiXEA7DN78Zu2zFCqiqIhSCV19t+xDLlsXOp5L67amnUi+iiHQt3bcmOS7DBRs2cGXF6zGLIvmSRUSkEwuH4eyzW472obYPItIB3TdITjA8ddX+25tuyUUoX7KISCeXaKS9oqKmtg/hMNxyi39sy6RJvg2zGfTu7VPBiUj31H2bWyQYnprduymJe0dSuUUnIiJ5tG9fy2UTJgA+MJ461Q/CV1bmh6ZO1oQuOqUbwKFDzVmONOqeSPfTfWuSoUWGC4BTT42d371bCeJFRDq1LVti5/v1a2osXFPjA+SGBv+YqNI5IlFKN4CHHspIKUWki+neQXK8vXtZsKDl4nvuyX1RREQkRfFtj2+/velpRYWvQS4u9o8VFckPkyilG8DFF3e4hCLSBXXvIDlB570Q4Rbtknftyl2RREQkTWPG0NRWrqTEzwdCId/E4qabWm9qAc0p3SJ69fKp4NTUQqR76t5BcoLOe9x3H8ccE7vZzp1qciEi0mlde21zYvvGxhZtKkIhuO661NJ5PvWUz2zkHHz4oQJkke6sewfJCYanZvdurryy5aZqciEi0gktXBjbAbuxEcrL81ceESkY3TtIhoSd96qq4PjjY5fV1eWoPCIikrpEvepqa3NfDhEpOAqS4+3dC/ghRqPt3p2HsoiIdBPV1T4F26xZqeUzJhyGKVPgjTdil5eUtOidl06eZBGRiO6bJzkiQec9wmFOPTXEyy83L46kggty04uISIZUV8O8ec3zv/89PPFEK22Iw2E47zyf1y3el74Us2M6eZJFRKKpJjlJ571EqeCWLMldsURE2svMLjCzV8xsm5ldm2D9T8xsSzC9amb7otZ9xcxeC6av5KK8K1bEzh892no+Y2pqEgfI0JQfOXrTVPMki4hEU5CcpPNeKNSykvntt3NXLBGR9jCzYuBOYAYwCrjUzEZFb+Oc+0fn3Fjn3FjgX4GHgn0HAT8AJgETgR+YWVy+n8yLT3NcWtp6PuNWO+bFJTVOJ0+yiEg0BcmQsPMewCc/GTu/d69SwYlIpzcR2Oace8M5Vwc8AFzUyvaXAvcHz6cDf3DO7XXOvQf8Abggq6XFN2NbutTnKJ45s42mFpC4Y55ZwqTG6eRJFhGJpjbJrViwAFaujF12zz1qlywindrxwFtR8zvxNcMtmNlJwMnAH1vZ9/j4/bKhqiqNa2uimuTvfjdpUuNQSMGxiKRPNcmJBBkuQiFajL733nt5KI+ISOoswTKXZNtLgN845yINfFPe18yqzGyzmW3es2dPO4rZAbW1sX1JJk/WqB8iknEKkiFphgtoHuk04rXXlEZIRDq1ncAJUfNDgV1Jtr2E5qYWae3rnKt2zk1wzk0YPHhwB4rrpZWmraICevTwDY179YJbb016zFmzYNSoNFLLiYgEFCRD0gwXAKee2nLzYJWISGf0NDDCzE42szJ8IPxI/EZmdipwDBAdOq4CppnZMUGHvWnBsqyKpGm7/nr/2GYwm0JD43DYVzCvXAkvv+wfp0xRoCwiqVOQDEkzXAAJU8E9+WQOyiQi0g7OuXrgG/jg9mXgQefcS2Z2o5l9LmrTS4EHnHMuat+9wE34QPtp4MZgWValnaYtHIbFi33k++KLSY9ZXx+7rM3UciIiUdRxLyJJhotQCIYNg+3bm5dt2eKv0eoIIiKdkXPuMeCxuGXfj5u/Icm+Pwd+nrXCJRBJ0xYZ8KPVNG2RKuJIBLxpk3+M6/VXUeGby0UHym2mlhMRiaKa5GT2NleejB3bcrWaXIiIZEZaadoSVRHHj0YSHHPdOp9S7rTTUkwtJyISRTXJEck674VCCVPBbd2au6KJiBS6lNO0VVT4PiSNjc3L4kcjiTrmww9npHgi0g2pJjmilc57iUbf+9//zWHZRETEe/HF2AB5zhwlrxeRrFCQHNFK5z1o2WRZo++JiGROdTUcdxz07QuVlXEryst9JUbv3nDddbE7RuVoXrjQ57YfNsy3Py4r8+2SS0t9szllthCRdChIjpak8x7A1Ve3XLZkSRbLIiLSTVRXw7x5vl7igw9g+fIgUI6s2LsXnINDh2L6iwAQ5GheuNAnvNi2DXbs8M2Wjx71GTPq6+H55+G88xQoi0jqFCSnqKqqZQz99tv5KYuISMEIh1lx2xvED+z3+MpD8O1vt71/UJP80ENtb9rQoBRwIpI6BcmtiauxmDy55Wo1uRARaadgFJHZr0eGlHZNjzM++C9frdyWoNPexRe3vWlxsVLAiUjqFCRHa2V4akg8sMjNN2e5TCIihSoYRaTKVbPU5jOkzwH69IE5Q9awjK+0vX/v3k2d9hYt8tfo4cPhpJOa2yIXF/vnZ54J69crBZyIpE5BcrRWMlxA4iwXO3aojZuISLtERhEpLqaq5y/56x9e4uBBWDb3D6ntP2tWzOyiRfDaa37wp6NH/eAkkbbJW7YoQBaR9ChIjtZGhguAT36y5W6LF2exTCIihSrRKCLhMPz4x23vO20aLFuW/TKKSLelIDleKxkuIHGTiyefzFJZREQKXShEuPzvuOWGI1QvfJ1bbjhCuOETibc1849JGhdHssWVlfl0cuXlcenkRETSkNKIe2Z2AfBToBi42zl3a9z6y4HbgL8Ei/7NOXd3sK4BeDFY/mfn3OcyUO7cieu8F2lyEV3BvHt30+B8IiKShnD1i0yddwpHOI3G1cUUcTI9WMMaphIiqgaiqMg3Mq6v91FwXJAcyRYXEblGL1/uH1XpLCLparMm2cyKgTuBGcAo4FIzG5Vg018758YG091Ryw9FLe/8AXIbnfcgcZOLa6/NYplERApUzYpa6iijMaizaaSIOkqpocJvUFzse91t2ABr18Y2zYiyYkXyczz+eJYKLyIFLZXmFhOBbc65N5xzdcADwEXZLVYetdF5DxI3uVi3Th34RETSVTG7nDLqKKIegCLqKeMoFTwBPXr4lBSRXnehkB9xL8FtuyATXEIzZmSr9CJSyFIJko8H3oqa3xksizfbzF4ws9+Y2QlRy3ua2WYze9LMZnaksDmRQue9UMgPexpPHfhERNITqhrDmgWr+aF9n6VU8UOuD5pahH0lRYqqqmDpUt+tpLTU3xQcNAjmzFFTCxFpn1TaJFuCZS5u/nfA/c65I2Y2H/hP4FPBuhOdc7vM7OPAH83sRefc6zEnMKsCqgBOPPHEtF5AVrTReQ98ZUZ0+zdQBz4RkfYIvfqfhNzKliuOHvW5lFPs8FFV1ZQ2WUSkw1KpSd4JRNcMDwV2RW/gnKt1zh0JZv8DOCtq3a7g8Q2gBhgXfwLnXLVzboJzbsLgwYPTegE5Edd5DxIPUx3pwCciIimqroaVCQLkiJdeyl1ZRESipBIkPw2MMLOTzawMuAR4JHoDMzsuavZzwMvB8mPMrEfw/FjgHGBrJgqeVSl03oOWw1QD/P3fZ6lMIiKFqLUedwBPPZWbcoiIxGkzSHbO1QPfAFbhg98HnXMvmdmNZhbJVvFNM3vJzJ4HvglcHiw/DdgcLF8L3Oqc6/xBatBxPwAAIABJREFUcgqd9yBxB74tW1SbLCKSqvDYq7iFawnj0wYt5GZ68AFFHOUEthOe9K08l1BEuitzLr55cX5NmDDBbd68Od/FgClTfMqKiJkz4eGHW2w2diw8/3zsssmT4Yknslw+EemUzOwZ59yEfJcjl9p73Q6HYepUqDvcQJk7wsX8huV8OWaboiJjwwbloReR7Gjtmq0R95JJofMewF13tVymdHAiIm2rqYG6w400uGLqKOVxIrnarGlqbPTbiYjkmoLkDlI6OBGR9qnYt5Iyd5hijlLGUWYQGfXDNU1FRQlHoBYRyToFyalKkOEi4rrrWi5bsyaLZRERKQChLXexhqncxPdZw1SW8RUWcCtlHMJoYGj//WpqISJ5oyA5mRQzXIBPB9e3b+yyAwd8ZiMREUli9mxCPMl13EqIJ6G4mEU9/pkjxf1p7NWft/57qwJkEckbBcnJpJjhIiJR6rdrrslCuURECkVkmLyJE33n6PXrYe1auOkmfztOEbKI5JGC5GRSGJ462qJF0KtX7LIDB2DhwiyUTUSkQITHVHHL+AcJD5kFQPWLIabXXMf0G0KMGJHaNbS6GsrLoaQERoxQx2kRyYxUhqXuvlLMcBHxD//QssPekiU+gBYRkVjhMEw9v4G6I8dTxuf5h/+4k8UNn8RntvAi19Rk19Hqapg3r3l+2zZfv6G2zCLSUapJTkcrnffAX8R79IhdVlcHlZVZLJOItEs4DCecAGaJp549dSco22pqoK7OaKCEOkp5qOGihNs99FDyYyQasE9p40QkExQktyaNznsRV1/dctny5br9J5ILkdvuyQLf6Onss2HnzuTHOnLE12IqUM6eigooK3NNKeAuLv5twu0uvjj5MWbPbrlMaeNEJBMUJLcmzc574GuT+/dvuVx5k0XaLxyGkSPbDnznzWvzhk/aWqvFlI4JhWDN2mJumr+LNfN/w6L157J0qTFtGkybBsOHw4IFrTdZi/T9GzQIiov9PmpqISKZoDbJrYl03osenrqVznsRt90W20YOYPXqDJdNpIBUV/tsMAcO5LskLbVWiykdFyJM6MQaX/UbClEV8oFvOqqq0t9HRKQtqkluS5qd9yBx3uQPP1TbZOmeKit91oG2aoA7W4Dco0fbtZjSQeEwTJ0K11/vH9UuTUQ6EQXJWZIob7LaJktXVVnpb2Wn0tY3flq+HBoa8v0KEispgTlzwLmW0+HDCpCzzvfco7rhCqYfepjqxe81rQqHYdw4/7krKYHjjmv+sVVUBJMmEbPtLbfo+ioimaXmFulKscHjokXws5/B/v2xy7/4RXjrrSyUS6Sdqqv90OqZbsubLyUl8KUvwbJl+S6JtKmigmqrYh53ArB6JVANY8b4lm6Njc2bRrd0cw42bfKB8pIlvhK6rg7KyjQGiYhkjmqS29KODBcRt93WctnOnWp2Ibk3aVJuO7tlQ1GR78yVqNY3ejp6VAFylxEKsWL8j4IZA4wVK3wFc3SAnMyzzzZVRtPQ4B+V+k1EMkVBclvakeEioqrK97SOp2YXkmnTp7fe5GHTpnyXsG2RNsDJgt+GBli1Kt+llEybfeUxRA8eMnu278NXlMK30/jxkTRyvllGWZlSv4lI5qi5RVvameEi4r77fD7WeNOmdb6OStJ5hcPwla/Aa6/luyTtM2iQbzOqDAQSL/KZWLHCB8iR+Q0bfN+OF17wP/QGD4Y9e/yPJTP4xCfgqaf8tmvW+BrkIEGGiEhGKEhORTsyXESEQr5j0PLlscsPHvQdUf761w6WTQpKZSXcf39qt5pzbehQePBBBSGSeYlSuIVC8Nxzqe0fCulzKSKZp+YW7ZFmA85ly+C001ou373bB8rS/SRLi7Z8eX4C5NayPESmt95SICIiIt2HguRUdKDzXsTWrS1zJ4MPlEtKfIYBKUzTp/v2lflMi2bWeqc3dXaTvAiHqZ71GJNG7WfWrJaX1epq//8zahSUlvohxyPL4v+nevfWEOIiklkKklPRgc570ZKNutfQ4DMM9OqlYLmrS5RFYvVqH4hmkxlMnJg8CG5sVKc36WTCYaon/5J5K2ew6eV+rFzpmDKlOVCurvbXxdWr4eWXob7e38SLLIv/nzp0CBYvVqAsIpmjIDkVkc570dLovBd9mKVLk68/fNh/ARxzjLJfdHYLF/psDLnMItFaCrTGxuZOTCJdQk0NK+ovCmZ8+rejR5tTuK1Y0b7DPvRQBsomIoKC5NR1oPNetKoq2LjRpypKZt8+nxGjZ0/ViuRbsrbDixf7nKzZMHy4/4woBZoUtIoKZhf/NphxgKO0tDmF2+zZ7TvsxRdnoGwiIihIzotQCI4cadnUOd6RIz4YKy1VsJwtbeUXzmbb4UGD/J2F+GD4tdfUQU66h6rie1jKPCayiZmT9/LEE82f/aoq//8xbZrv+FxS0vw/M22a//+M1quXz7OtocRFJFMUJLdXBoYo++tf/UW9raT59fU+WC4u1mh97ZVsxLlk7cQzySxx7XBtrfIGSzdWUwMNDVTxHzxlIR4e9U8tfhxWVfm7J1u3+s6lkf+ZVat8E6Po/6cPP1SALCKZpSA5VRnIcJHIokW+pnLBgpY1I/EaG33NZiTAO+EEtV2OtnChr03K54hzibJINDaqdlikhYoK/8sf/D/KvffqgiYinYqC5FRlKMNFMosW+UPOmZP6Pjt3+rbLkUCwuNg3Hyhk4TCMHJk4EF682Hd+zJX+/Vs2l1AWCZEUhUJw4YUAhPkkt9R9m/B9XXRISREpSAqSU5WhDBdtWbbMB1sLFjRXsqSqsdE3H2itjW381Nk6BybKfxo9nX127odmTtZ2+P331VxCpN3CYXj0UcJ8kqms4Xp3I1PvuUyVySLSaShITkeGMlykYtEi3xZ5wYLWM2F0VKRzYDqBdbo11pWVfp9Ujp2LnMLR2hpkQ22HRbIkaJNcQwV1lNFACXX11pQCTkQk3xQkd0QGOu+1ZdEiH8hu3AhDh2b9dClJt8Y6X0MtR0uWY1jNI0TypKICSkupoIYy6ijmKGVlzSngRETyTUFyOrLUeS8VoRC89VZzcDdnTttZMbqjRO2ElWNYpBMKhaCmhtD8sayZ+W/cNH8Xa9YWq4OriHQaCrPSkeXOe+lYtswHfpEgcONGGDEiL0XJueJi/yMhUdMItRMW6WJOPJHQgvO47q6TFCCLSKeiIDkdOeq81x6hELz6autta+OnpUuhX798l7ylZCPORab6ev8jQUS6sHAYpk6F66/3j+qxJyKdjILkdOWw8162VVXB/v3pBdbtrbEeOrT1wFcjzol0MzU1fmz3hgb/qB57ItLJlOS7AF1eDjrvdSaRGmsRkQ6pqICyMqoPf5kV7vPM3vdx1FJKRDoTBcnpStZ5T1WfIiKpC4Wo/ocXmbf44+Bg9WKDU9SnQEQ6DzW3SFcn6rwnItKVrdhyCmDB9P+3d+/RUdV3v8ffXwMB5VIFtVpQQRa1XIQQU+vUS4eDIurjtfZRHq1KrRHt5TztUYSnS3seWUsKrT3U064K51RXVcS76HHZgxrJsa2pcg1qkIISlJumwQoiGC7f88feCclkkkzCzOyd5PNaa6+Z/dt79v5mz8yPL7/5/X4bnn460nBERJpQktxeMR68JyLSmXz7262vi4hESd0tOqILDd4TEYlKfdeKp58OEmR1tRCROFGSLCIikSktVXIsIvGk7hbZ0M1muBARERHp6pQkd0SEt6cWEWmLmU0ys7Vmtt7Mprewz7+aWZWZvWNmjzYq329mq8Ll+fxFLSISL0qSO0IzXIhITJlZAfA74AJgJDDZzEam7DMcmAGc6e6jgH9vtHm3uxeFyyX5iltEJG6UJHeEZrgQkfg6HVjv7u+7ex3wGHBpyj43Ab9z908A3P3jPMcoIhJ7SpI7SjNciEg8DQI+bLS+KSxr7KvAV83sr2b2NzOb1GhbbzNbFpZf1tJJzKw03G9ZTU1N9qIXEYkJzW6RLRq8JyLxYGnKPGW9BzAcSAKDgT+b2Wh3/ydwortvMbOTgVfN7C13f6/ZAd3nA/MBSkpKUo8vItLpqSW5ozR4T0TiaRNwQqP1wcCWNPs85+573X0DsJYgacbdt4SP7wPlwLicRVpRAbNmqe4UkVhSktxRGrwnIvG0FBhuZkPNrBC4GkidpWIRMB7AzI4m6H7xvpkdZWa9GpWfCVTlJMqKCpgwAe68M3hUoiwiMZNRktzWdEJmdoOZ1TSaNuj7jbZdb2brwuX6bAYfKQ3eE5EYcvd9wA+BxcAa4Al3f8fM7jaz+tkqFgO1ZlYFLAFud/daYASwzMwqw/JfuHtOkuSKh9Zxy+5fc8v+/0nFF8VQXp6L04iIdFibfZIbTSd0HsFPdEvN7Pk0Fefj7v7DlNcOAH4OlBD0iVsevvaTrEQfNQ3eE5EYcvcXgRdTyu5q9NyBn4ZL431eB07NdXwVFZD8wzXUhe00Dx6YwpKB60jk+sQiIu2QSUtyJtMJteR84GV33x4mxi8Dk9p4TeeROlivujqSMEREOpPycti7r4BgjKFRZ70or815bi4i0i6ZJMmZTCcE8G0zW21mT5lZ/aCRTF/bOe3Z03S9slL96kRE2pBMQs+eB9cLC41kMqpoRETSyyRJzmQ6of8DDHH3McArwB/b8drOO9/mjTc2XXfX4D0RkTYkEkFr8tSpwbJkSVAmIhInmSTJbU4n5O617v5FuPq/gNMyfW34+vnuXuLuJcccc0ymsUevtBSKipqWafCeiEibElTw+xNn8fvrKpQgi0gsZXIzkYbphIDNBNMJ/VvjHczseHffGq5eQjCiGoIR1PeY2VHh+kRgxiFHHSf9+zddV79kEZHW1U//VlcHhYVQVqamZBGJnTZbkjOcTujHZvZOOG3Qj4EbwtduB2YSJNpLgbvDsq5D/ZJFRNqnvDxIkPfvDx41/ZuIxFBGt6XOYDqhGbTQQuzuDwAPHEKM8XbjjfDmmwfX6/slq1VERCS9ZDJoQa5vSdaoPRGJId1x71CVlsLw4U3LqnJzgyoRkS4hkQi6WMycqa4WIhJbGbUkSxt6pFzGjRujiUNEpLNIJJQci0isqSU5G045pen6xo3qlywiIiLSiSlJzoZp05qXzZmT/zhEREREJCuUJGdDIgFDhjQtW7s2klBERERE5NApSc6WE09sut6rVzRxiIiIiMghU5KcLQMGNF3XfMkiIi2qqIBZs1RNikh8aXaLbDnuuKbrmi9ZRCQt3XBPRDoDtSRny3XXNS/TfMkiIs3ohnsi0hkoSc6WdIP3/v73SEIREYmz+hvuFRTohnsiEl9KkrOpqKjp+rZtMH9+NLGIiMSUbrgnIp2BkuRsSjdf8h/+kP84RERiLpGAGTOUIItIfClJzqZEAoYPb1pWVxdNLCIiIiLSYUqSs61HyoQh27ZFE4eIiIiIdJiS5Gw75ZSm6+qXLCIiItLpKEnONvVLFhEREen0lCRnW7p+yZ98Ek0sIiIiItIhSpJz4aijmq6vW6d7r4qIiIh0IkqSc+HGG5uXzZmT/zhEREREpEOUJOdCaSkMGNC0bOXKaGIRERERkXbr0fYu0iH9+8P27QfXd+6MLhYRkZipqICHHgqeX3edbioiIvGjluRcSb1F9fbtmgpORIQgQU4m4f77g2X8eA3bEJH4UZKcK+mmgps7N/9xiIjETHk57N17cL2uLigTEYkTJcm5kkjAccc1Lfvoo2hiERGJkWQSevY8uF5YGJSJiMSJkuRcOuOMpuvqciEiQiIRtBxPnRosS5aoT7KIxI+S5FxK1+XinnvyH4eISMwkqOD3J87i99dVKEEWkVjS7Ba5VN/lYtu2g2UbNwYjVPSvgoh0VxUVMGFC0Bm5sBDKylQnikjsqCU511K7XIBuLCIi3Vt5OdTVUbH/68za8xMqHloXdUQiIs2oJTnXpk2DRYualv3tb9HEIiISB8kkFQVnMWH/i9R5IYUPGmWaK1lEYkYtybmWbpaLbds0KaiIdF+JBOXf+yN11pv99KBuX4GmgBOR2FGSnA/pulxMn57/OEREYiJ53UkU9j6MggJNASci8aQkOR/SzXLx2mtqTRaRbiuRCMbrzZypcXsiEk/qk5wPiQQMGQLV1U3L58yBZ5+NIiIRkcglEkqORSS+1JKcLzNmNC8rK8t/HCIiIiLSJiXJ+VJaCn37Ni3buVN34BMRERGJISXJ+XTrrc3Lbrst/3GIiESsYv5bzDq/nIr5b0UdiohIWkqS82n2bDj88KZlO3fC+edHE4+ISAQq5r/FhJuHcedLZzHh5mFKlEUklpQk59uPftS87KWX1O1CRLqN8qdrqaMwmCOZnpQ/XRt1SCIizShJzrfZs6F//+bl6nYhIt1E8tsDKaSOAvZSyF6S3x4YdUgiIs0oSY7CL3/ZvGznTrj22vzHIiKSZ4nSUymb9x4zJ/6VsnnvkSg9NeqQRESaMXePOoYmSkpKfNmyZVGHkXvDh8P69c3LX39dE4eKdGJmttzdS6KOI5+6Tb0tIl1Oa3W2WpKj8tBD6csvvTS/cYiIiIhIM0qSo5JIpL9ddU2Nul2ISLdQUQGzZgWPIiJxoyQ5SrNnw+DBzcsXLNC/GiLSpVVUwIQJcOedwaOqPBGJGyXJUXviifTl6nYhIl1YeTnU1cH+/cFjeXnUEYmINKUkOWqtdbvQTUZEpItKJqGwEAoKgsdkMuqIRESaUpIcBy11u3jpJfVPFpEuKZGAsjKYOTN41KQ+IhI3PaIOQEJPPAHf/Gbz8gULYNCgIJEWEelCEgklxyISXxm1JJvZJDNba2brzWx6K/tdaWZuZiXh+hAz221mq8Ll/mwF3uW01O0CYM4cjWoRERERyaM2W5LNrAD4HXAesAlYambPu3tVyn79gB8Db6Qc4j13L8pSvF3b7NmwalXQzSLVhAnw+ef5j0lEJAcqKg5OF3/ddWpRFpH4yaQl+XRgvbu/7+51wGNAuqkXZgJzgD1ZjK/7WbwYRoxoXr57N/Tvn/94RESyrKIiGKh3//3BMn68fiwTkfjJJEkeBHzYaH1TWNbAzMYBJ7j7C2leP9TMVprZ/zOzs9OdwMxKzWyZmS2rqanJNPauq6oKTjqpefnOnXDEEfrXREQ6tfJy2Lv34LqmgBOROMokSbY0Zd6w0eww4H8A/y3NfluBE919HPBT4FEza9Yc6u7z3b3E3UuOOeaYzCLv6qqrYcCA5uW7dwcD/ObPz3tIIiLZkExCz54H1zUFnIjEUSZJ8ibghEbrg4Etjdb7AaOBcjOrBs4AnjezEnf/wt1rAdx9OfAe8NVsBN4t1NZCv37pt918M9xxR37jEZFOIZPB1mb2r2ZWZWbvmNmjjcqvN7N14XJ9LuJLJIKW46lTg2XJEvVJFpH4yWQKuKXAcDMbCmwGrgb+rX6ju38KHF2/bmblwG3uvszMjgG2u/t+MzsZGA68n8X4u74dO2DgQNi+vfm2OXOCgX6LF+c/LhGJpUwGW5vZcGAGcKa7f2Jmx4blA4CfAyUEvxguD1/7Sbbj1PRvIhJ3bbYku/s+4IfAYmAN8IS7v2Nmd5vZJW28/BxgtZlVAk8BU909TbYnraqtTd/1AoKZMI4/Pr/xiEicZTLY+ibgd/XJr7t/HJafD7zs7tvDbS8Dk/IUt4hIrGR0MxF3fxF4MaXsrhb2TTZ6/jTw9CHEJ/Vqa4NkeNu25tu2bYPDDoPbb9dNR0Qk3WDrb6Ts81UAM/srUAD8d3f/vy28dhC5UFER9LlIJtWkLCKxpDvudSZbt8KQIbBxY/Nt7kH3i4ceCvYTke6q1cHWoR4E3d+SBONM/mxmozN8bXASs1KgFODEE09sX4QVFcHc73V1wag93ZdaRGIoozvuSYxUV8Ppp7e8fds2MINrr81bSCISK20Ntq7f5zl33+vuG4C1BElzJq8FDnFWovLyIEHev1/zv4lIbClJ7ozeeAPmzQu6WLRkwQLo1UtTxYl0Pw2Drc2skGCw9fMp+ywCxgOY2dEE3S/eJxh7MtHMjjKzo4CJYVl2JZNBC3JBgeZ/E5HYUpLcWZWWBq0w6e7OV6+uLpgqbsiQvIUlItHKcLD1YqDWzKqAJcDt7l4bDqyeSZBoLwXuzslg60Qi6GIxc6a6WohIbJl72u5mkSkpKfFly5ZFHUbnMn8+3HILHDjQ+n7XXAOPPJKfmES6KTNb7u4lUceRT6q3RaSzaq3OVktyV5BJqzKoC4aIiIhIhpQkdyVVVUFf5V69Wt6nvgvGsccGI8xFREREpBklyV1NaSns2QPTprW+X00NfPObSpZFRERE0lCS3FXNnh3MndxWF4z6ZLmwEO64Iz+xiYiIiMSckuSurr4LRs+ere+3d29wMxIzOOEEtS6LiIhIt6YkuTsoLQ36Il9zTWb7b9oUtC4XFOimJCIiItItKUnuTh55JOiCkWmyfOBAMCOGGRxxhLpjiIiISLeheZK7s2uvDZLg9howAGbNClqoRaQJzZMs0r3s3buXTZs2sWfPnqhDkVb07t2bwYMH0zOl+2lrdbaSZAnmTZ4xA7Z34MZahx8OP/pRMFBQRJQki3QzGzZsoF+/fgwcOBAzizocScPdqa2tZefOnQwdOrTJNt1MRFpXWgq1tQe7YrTnS75798EBfz16qA+ziGSkoiL4QUpjhKWz27NnjxLkmDMzBg4c2O7WfiXJ0tQjjwR9kV9/HQYPbt9r9+8/2IdZ/ZhFpAUVFTBhAtx5Z/CoRFk6OyXI8deR90hJsqSXSMCHHwaty/PmQb9+7T9G41bm+kXTy4l0e+XlUPeFs39/8FheHnVEIp1XbW0tRUVFFBUVcdxxxzFo0KCG9bq6uoyOMWXKFNauXdvuc1900UWcffbZ7X5dZ6EkWdpWWgo7dhzsjlFQ0PFj1U8vp8RZpNtKDnyLwgO7KWAvhQd2kxz4VtQhiXRaAwcOZNWqVaxatYqpU6fyk5/8pGG9sLAQCPrkHjhwoMVjPPjgg5xyyintOm9tbS1vvfUWH330ER988MEh/Q1xpSRZ2ueRR2DfviBhnjYNevc+9GOmJs4FBXD++Yd+XBGJpUTtC5QdNpGZ3EXZYRNJ1L4QdUgi+ZWHTvnr169n9OjRTJ06leLiYrZu3UppaSklJSWMGjWKu+++u2Hfs846i1WrVrFv3z6OPPJIpk+fztixY0kkEnz88cdpj//UU09x2WWXcdVVV/H44483lG/bto1LL72UMWPGMHbsWN544w0gSMTry6ZMmZKzvzublCRLx82eHXSpcO9YH+aWHDgAL73UtLVZ/ZtFuo5kkkSvFcwo+CWJXisgmYw6IpH8yWOn/KqqKm688UZWrlzJoEGD+MUvfsGyZcuorKzk5ZdfpqqqqtlrPv30U771rW9RWVlJIpHggQceSHvshQsXMnnyZCZPnszChQsbyn/wgx9w3nnnsXr1apYvX86IESOorKxk9uzZlJeXU1lZyb333puzvzmblCRLdjTuw5zNVuZ66fo3K3EW6ZwSCSgrg5kzg8dEIuqIRPKnvDy4C+7+/cFjDjvlDxs2jK9//esN6wsXLqS4uJji4mLWrFmTNkk+/PDDueCCCwA47bTTqK6ubrbP5s2b+eCDDzjjjDMYOXIk+/fv59133wWgvLycm2++GYAePXrQv39/Xn31Va666ioGDBgA0PAYd0qSJTcatzLXL4fanzlVusTZDAYODOZ+FpH4SiSC+dmVIEt3k0xCYWHw72FhYU5/SenTp0/D83Xr1vGb3/yGV199ldWrVzNp0qS0U6LV92MGKCgoYN++fc32efzxx6mtrWXo0KEMGTKEDz74gMcee6xhe+pMEu7eKWcAUZIs+dO4P3OuEmcIbopy881KnkVEJH4i+iVlx44d9OvXj/79+7N161YWL17c4WMtXLiQV155herqaqqrq3nzzTcbulyMHz+e+++/H4D9+/ezY8cOzj33XB577DG2hzct296Rm5dFQEmyRCs1cX79dRg+PDfnail5Puyw4JyaYUNERPIhgl9SiouLGTlyJKNHj+amm27izDPP7NBx3nvvPbZt20ZJycGb1A0fPpxevXqxfPlyfvvb37J48WJOPfVUSkpKePfddxkzZgzTpk3jnHPOoaioiNtvvz1bf1ZO6bbUEn933AH33QftvFNOVhQUwNVXB8m8SAZ0W2qR7mXNmjWMGDEi6jAkA+neK92WWjq3dP2bsz0wsCWpdxFUK7SIiEi3oCRZOqd0iXN98txo0EHOucP69c1vkJJu0U1TREREOg0lydK1zJ4NX3zRPHnOxQDB9kp3t8G2Fg02FBERiYSSZOke0s2sUb9MnBgkpHHU0mDDtpbDDoNvfCPq6EVERDotJckiixcHd/lLTZ6zeRfBfHOHN99sf3KtVmwRERFASbJIy1LvIpguiS4qClptu6KOtmJrQKOIiHQBXfRfd5E8SCRg5cpgBoyWEunGfaK7ajKdTnsGNLa26NbjIiKtSiaTzW4MMnfuXG699dZWX9e3b18AtmzZwpVXXtnisdua3nHu3Ll8/vnnDesXXngh//znPzMJPSNjx45l8uTJWTtee3Sjf7VFIvTII5kl03EbbBi1lm493tGlZ0+49tqo/yoRkayZPHlyk1tCAzz22GMZJ5Zf+cpXeOqppzp8/tQk+cUXX+TII4/s8PEaW7NmDQcOHOC1115j165dWTlmeyhJFomr1gYbtrXEeTBilPbta33e68ZL795qxc6ligqYNUtdcqRbyubH/8orr+SFF17giy++AKC6upotW7Zw1lln8dlnnzFhwgSKi4s59dRTee6555q9vrq6mtGjRwOwe/durr76asaMGcNVV13F7t27G/a75ZZbKCkpYdSoUfz85z8H4L777mPLli2MHz+e8ePHAzBkyBD+8Y9/APDrX/+a0aNHM3r0aObOndtwvhEjRnDTTTcxatQoJk6c2OQ8jT366KNZ0FbWAAALl0lEQVR897vfZeLEiTz//PMN5evXr+fcc89l7NixFBcX89577wEwZ84cTj31VMaOHcv06dMP6boC4O6xWk477TQXkYhdc417QUFH0vOut0yb1q5LByzzGNSl+VzaXW+//rr74YcHn7HDDw/WRTqpqqqqdu2fi4//hRde6IsWLXJ391mzZvltt93m7u579+71Tz/91N3da2pqfNiwYX7gwAF3d+/Tp4+7u2/YsMFHjRrl7u733nuvT5kyxd3dKysrvaCgwJcuXeru7rW1te7uvm/fPv/Wt77llZWV7u5+0kkneU1NTUMs9evLli3z0aNH+2effeY7d+70kSNH+ooVK3zDhg1eUFDgK1eudHf373znO/7www+n/buGDx/u1dXVvnjxYr/44osbyk8//XR/5pln3N199+7dvmvXLn/xxRc9kUj4rl27msTbWLr3qrU6Wy3JItLcobRi1w9o7Cot2c88E3UEXU95OdTVBV2Q6uqCdZFuIhcf/8ZdLhp3tXB3/uM//oMxY8Zw7rnnsnnzZj766KMWj/Paa69xbdglbcyYMYwZM6Zh2xNPPEFxcTHjxo3jnXfeoaqqqtWY/vKXv3D55ZfTp08f+vbtyxVXXMGf//xnAIYOHUpRUREAp512GtXV1c1ev3TpUo455hhOOukkJkyYwIoVK/jkk0/YuXMnmzdv5vLLLwegd+/eHHHEEbzyyitMmTKFI444AoABAwZkculapSRZRLKrfkBjumn12rPMmwf9+kX918AVV0QdQdeTTAZ3xiwoCB6TyagjEsmbXHz8L7vsMsrKylixYgW7d++muLgYgAULFlBTU8Py5ctZtWoVX/7yl9mzZ0+rx7I0DRwbNmzgV7/6FWVlZaxevZqLLrqozeMEjbTp9erVq+F5QUEB+/bta7bPwoULeffddxkyZAjDhg1jx44dPP300y0e193Txn4olCSLSDyVlsKOHdnrODFvHrSnZaFXr+A257Nn5+5v7K4SCSgrg5kzg8dEIuqIRPImFx//vn37kkwm+d73vtdkwN6nn37KscceS8+ePVmyZAkbN25s9TjnnHMOCxYsAODtt99m9erVAOzYsYM+ffrwpS99iY8++og//elPDa/p168fO3fuTHusRYsW8fnnn7Nr1y6effZZzj777Iz+ngMHDvDkk0+yevVqqqurqa6u5rnnnmPhwoX079+fwYMHs2jRIgC++OILPv/8cyZOnMgDDzzQMIhw+/btGZ2rNT0O+QgiIp1BaWmwSDwkEkqOpdvKxcd/8uTJXHHFFU1murjmmmu4+OKLKSkpoaioiK997WutHuOWW25hypQpjBkzhqKiIk4//XQgmIZt3LhxjBo1ipNPPpkzzzyz4TWlpaVccMEFHH/88SxZsqShvLi4mBtuuKHhGN///vcZN25c2q4VqV577TUGDRrEoEGDGsrOOeccqqqq2Lp1Kw8//DA333wzd911Fz179uTJJ59k0qRJrFq1ipKSEgoLC7nwwgu55557Mrp2LbHWmsOjUFJS4m3NySciEldmttzdS6KOI59Ub0t3tmbNGkaMGBF1GJKBdO9Va3W2uluIiIiIiKRQkiwiIiIikkJJsoiIiIhICiXJIiIiIocgbuO7pLmOvEdKkkVEREQ6qHfv3tTW1ipRjjF3p7a2lt69e7frdZoCTkRERKSDBg8ezKZNm6ipqYk6FGlF7969GTx4cLteoyRZREREpIN69uzJ0KFDow5DckDdLUREREREUihJFhERERFJoSRZRERERCRF7G5LbWY1wMYOvPRo4B9ZDudQKabMKKbMKKbMRB3TSe5+TITnz7suVG/HLR5QTJlSTJlRTM21WGfHLknuKDNb1tK9t6OimDKjmDKjmDITx5gkvbi9V3GLBxRTphRTZhRT+6i7hYiIiIhICiXJIiIiIiIpulKSPD/qANJQTJlRTJlRTJmJY0ySXtzeq7jFA4opU4opM4qpHbpMn2QRERERkWzpSi3JIiIiIiJZ0SWSZDObZGZrzWy9mU3P43lPMLMlZrbGzN4xs/8alg8ws5fNbF34eFRYbmZ2XxjnajMrzlFcBWa20sxeCNeHmtkbYTyPm1lhWN4rXF8fbh+So3iONLOnzOzd8FolYnCNfhK+Z2+b2UIz653v62RmD5jZx2b2dqOydl8XM7s+3H+dmV2fg5h+Gb53q83sWTM7stG2GWFMa83s/EblWftOpoup0bbbzMzN7OhwPS/XSQ6N6uxmccWqzg7PFat6Ow51dnhs1dsdjKnRts5Tb7t7p16AAuA94GSgEKgERubp3McDxeHzfsDfgZHAHGB6WD4dmB0+vxD4E2DAGcAbOYrrp8CjwAvh+hPA1eHz+4Fbwue3AveHz68GHs9RPH8Evh8+LwSOjPIaAYOADcDhja7PDfm+TsA5QDHwdqOydl0XYADwfvh4VPj8qCzHNBHoET6f3SimkeH3rRcwNPweFmT7O5kuprD8BGAxwfy8R+fzOmk5pM+96uzmccWqzg6PH5t6m5jU2eHxVG93MKawvFPV23k7Uc7+AEgAixutzwBmRBTLc8B5wFrg+LDseGBt+HweMLnR/g37ZTGGwUAZ8F+AF8IP3T8afVkarlf4QU2Ez3uE+1mW4+kfVm6WUh7lNRoEfBh+8XqE1+n8KK4TMCSlYmvXdQEmA/MalTfZLxsxpWy7HFgQPm/yXau/Trn4TqaLCXgKGAtUc7Cyzdt10tLh91J1dtMYYlVnh8eOVb1NjOrs8JhN6qP2Xpdc1Efp6shG21Rvd3DpCt0t6r889TaFZXkV/pwzDngD+LK7bwUIH48Nd8tHrHOBacCBcH0g8E9335fmnA3xhNs/DffPppOBGuDB8OfE/21mfYjwGrn7ZuBXwAfAVoK/eznRXqd67b0u+f78f4/gf/yRxmRmlwCb3b0yZVNcrpO0LBbvhersVsWq3o55nQ2qtzPSGevtrpAkW5oyz2sAZn2Bp4F/d/cdre2apixrsZrZvwAfu/vyDM+Zj2vXg+Anl9+7+zhgF8HPUS3JeUxhf7FLCX5q+grQB7iglfNG/hlrJYa8xWZmPwP2AQuijMnMjgB+BtyVbnMUMUm7RP5eqM5uU6zq7U5aZ0MM6iPV24emKyTJmwj6uNQbDGzJ18nNrCdBZbvA3Z8Jiz8ys+PD7ccDH+cp1jOBS8ysGniM4Oe7ucCRZtYjzTkb4gm3fwnYnsV46s+xyd3fCNefIqh8o7pGAOcCG9y9xt33As8A3yTa61SvvdclL5//cMDEvwDXePi7V4QxDSP4x7Iy/KwPBlaY2XERxiSZU519UBzr7PrzxKnejnOdDaq3M9Ep6+2ukCQvBYaHo1wLCTrpP5+PE5uZAX8A1rj7rxtteh64Pnx+PUG/t/ry68KRnGcAn9b/RJMN7j7D3Qe7+xCC6/Cqu18DLAGubCGe+jivDPfP6v/S3H0b8KGZnRIWTQCqiOgahT4AzjCzI8L3sD6myK5TI+29LouBiWZ2VNjaMjEsyxozmwTcAVzi7p+nxHq1BSPJhwLDgTfJ8XfS3d9y92PdfUj4Wd9EMBhrGxFeJ8mY6uxQHOvsMK641dtxrrNTz6d6O41OW2/nswN0rhaCkZF/JxiZ+bM8nvcsgqb/1cCqcLmQoO9TGbAufBwQ7m/A78I43wJKchhbkoMjpU8m+BKsB54EeoXlvcP19eH2k3MUSxGwLLxOiwhGqUZ6jYD/BN4F3gYeJhjpm9frBCwk6F+3l6DCuLEj14Wgv9n6cJmSg5jWE/QLq/+M399o/5+FMa0FLmhUnrXvZLqYUrZXc3AASF6uk5ZD/uyrzm4eW5KY1NnhuWJVbxODOjs8turtDsaUsr2aTlBv6457IiIiIiIpukJ3CxERERGRrFKSLCIiIiKSQkmyiIiIiEgKJckiIiIiIimUJIuIiIiIpFCSLCIiIiKSQkmyiIiIiEgKJckiIiIiIin+P5rcXYXLs0iYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.729\n",
      "roc-auc is 0.796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
